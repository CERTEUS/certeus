+=============================================================+
|                       CERTEUS — HEART                        |
+=============================================================+
CERTEUS PACK — Context for AI assistants (Claude/GPT/Gemini).
PL: Pliki repo są oddzielone '===== FILE: … ====='.
EN: Files are delimited by '===== FILE: … ====='.
Guidance: read sequentially; do not assume missing files exist; respect file boundaries.



===== FILE: tests/services/test_lexlog.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/services/test_lexlog.py           |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                         CERTEUS                             |
# |                   LEXLOG Parser Tests                       |
# +-------------------------------------------------------------+

"""
PL: Testuje minimalny parser LEXLOG na pliku kk.lex.
EN: Tests the minimal LEXLOG parser on kk.lex file.
"""

from __future__ import annotations

from pathlib import Path

from services.lexlog_parser.parser import parse_lexlog


def test_lexlog_parser_kk_lex() -> None:
    lex_path = Path("packs") / "jurisdictions" / "PL" / "rules" / "kk.lex"
    assert lex_path.exists(), "Missing packs/jurisdictions/PL/rules/kk.lex"

    content = lex_path.read_text(encoding="utf-8")
    ast = parse_lexlog(content)

    # Defines present
    names = {d.name for d in ast.defines}
    assert {
        "cel_korzysci_majatkowej",
        "wprowadzenie_w_blad",
        "niekorzystne_rozporzadzenie_mieniem",
    }.issubset(names)

    # Premises present
    pids = {p.id for p in ast.premises}
    assert {"P_CEL", "P_WPROWADZENIE", "P_ROZPORZADZENIE"}.issubset(pids)

    # Rule ties premises to conclusion
    rule = next(r for r in ast.rules if r.id == "R_286_OSZUSTWO")
    assert rule.conclusion == "K_OSZUSTWO_STWIERDZONE"
    assert set(rule.premises) == {"P_CEL", "P_WPROWADZENIE", "P_ROZPORZADZENIE"}

    # Conclusion has assertion
    concl = next(c for c in ast.conclusions if c.id == "K_OSZUSTWO_STWIERDZONE")
    assert concl.assert_expr is not None and "cel_korzysci_majatkowej" in concl.assert_expr

```


===== FILE: tests/services/test_lexlog_eval.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/services/test_lexlog_eval.py      |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                         CERTEUS                             |
# |                   LEXLOG Evaluator Tests                    |
# +-------------------------------------------------------------+

"""
PL: Testy ewaluatora LEXLOG (MVP) dla art. 286 k.k., z loaderem mapowania.
EN: LEXLOG evaluator tests (MVP) for art. 286 PC, with mapping loader.
"""

from __future__ import annotations

from pathlib import Path

from services.lexlog_parser.evaluator import choose_article_for_kk, evaluate_rule
from services.lexlog_parser.mapping import load_mapping
from services.lexlog_parser.parser import parse_lexlog


def _load_kk_ast():
    lex_path = Path("packs") / "jurisdictions" / "PL" / "rules" / "kk.lex"
    content = lex_path.read_text(encoding="utf-8")
    return parse_lexlog(content)


def _load_ctx():
    map_path = Path("packs") / "jurisdictions" / "PL" / "rules" / "kk.mapping.json"
    assert map_path.exists(), "Missing kk.mapping.json"
    return load_mapping(map_path)


def test_286_passes_when_wprowadzenie_true_and_excludes_false() -> None:
    ast = _load_kk_ast()
    ctx = _load_ctx()

    flags = {
        "ZNAMIE_WPROWADZENIA_W_BLAD": True,
        "ZNAMIE_POWIERZENIA_MIENIA": False,
    }
    res = evaluate_rule(ast, "R_286_OSZUSTWO", flags, ctx)
    assert res.satisfied is True
    assert res.missing_premises == []
    assert res.failing_excludes == []
    assert choose_article_for_kk(ast, flags, ctx) == "art286"


def test_286_fails_when_excluded_flag_set() -> None:
    ast = _load_kk_ast()
    ctx = _load_ctx()

    flags = {
        "ZNAMIE_WPROWADZENIA_W_BLAD": True,
        "ZNAMIE_POWIERZENIA_MIENIA": True,  # exclude -> blokuje
    }
    res = evaluate_rule(ast, "R_286_OSZUSTWO", flags, ctx)
    assert res.satisfied is False
    assert res.failing_excludes == ["ZNAMIE_POWIERZENIA_MIENIA"]
    assert choose_article_for_kk(ast, flags, ctx) is None

```


===== FILE: tests/services/test_lexlog_parser.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/services/test_lexlog_parser.py    |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                          CERTEUS                            |
# +-------------------------------------------------------------+
# | FILE: tests/services/test_lexlog_parser.py                  |
# | ROLE: Unit tests for LEXLOG parser AST & legacy stub        |
# | PLIK: tests/services/test_lexlog_parser.py                  |
# | ROLA: Testy parsera LEXLOG (AST i zgodność legacy)          |
# +-------------------------------------------------------------+

"""
CERTEUS — LEXLOG Parser Tests
PL: Testy sprawdzające parsowanie: DEFINE/PREMISE/RULE/CONCLUSION,
    normalizację ID oraz zgodność z legacy stubem.
EN: Tests for parsing of DEFINE/PREMISE/RULE/CONCLUSION, canonical ID
    normalization, and legacy stub compatibility.
"""

from pathlib import Path

from services.lexlog_parser.parser import LexlogParser

RULES = Path("packs/jurisdictions/PL/rules/kk.lex")


def test_lexlog_parses_art_286_rule():
    text = RULES.read_text(encoding="utf-8")
    ast = LexlogParser().parse(text)
    assert ast, "AST should not be empty"
    assert ast["rule_id"] == "R_286_OSZUSTWO"
    assert ast["conclusion"] == "K_OSZUSTWO_STWIERDZONE"
    assert set(ast["premises"]) == {"P_CEL", "P_WPROWADZENIE", "P_ROZPORZADZENIE"}
    assert "z3.And(" in ast["smt_assertion"]

```


===== FILE: tests/services/test_limits.py =====
```text
# +=====================================================================+
# |                              CERTEUS                                |
# +=====================================================================+
# | FILE / PLIK: tests/services/test_limits.py                          |
# | ROLE / ROLA:                                                         |
# |  EN: Unit tests for per-tenant limits hook (budget/rate).           |
# |  PL: Testy jednostkowe hooka limitów per-tenant (budżet/limit).     |
# +=====================================================================+

from __future__ import annotations

import pytest
from fastapi import HTTPException
from starlette.requests import Request  # FastAPI re-exports this class

from services.api_gateway.limits import enforce_limits, get_tenant_id, set_tenant_quota


def _make_request(headers: dict[str, str] | None = None) -> Request:
    """
    EN: Build a real Starlette/FastAPI Request from raw ASGI scope.
    PL: Zbuduj realny obiekt Request na bazie surowego scope ASGI.
    """
    raw = []
    if headers:
        for k, v in headers.items():
            raw.append((k.lower().encode("ascii"), v.encode("utf-8")))
    scope = {"type": "http", "headers": raw}
    return Request(scope)  # type: ignore[arg-type]


def test_get_tenant_id_header_and_fallback() -> None:
    """
    EN: Extract tenant from header; fallback to 'anonymous'.
    PL: Pobiera tenant z nagłówka; w przeciwnym razie 'anonymous'.
    """
    r1 = _make_request({"X-Tenant-ID": "t-42"})
    assert get_tenant_id(r1) == "t-42"
    r2 = _make_request()
    assert get_tenant_id(r2) == "anonymous"


def test_enforce_limits_success_and_exhaustion() -> None:
    """
    EN: Budget charges succeed until exhausted; next call raises 429.
    PL: Pobrania z budżetu działają do wyczerpania; kolejny wywołuje 429.
    """
    tenant = "t-budget"
    set_tenant_quota(tenant, 2)
    r = _make_request({"X-Tenant-ID": tenant})

    # dwa zużycia — OK
    enforce_limits(r, cost_units=1)
    enforce_limits(r, cost_units=1)

    # trzecie powinno przerwać
    with pytest.raises(HTTPException) as ex:
        enforce_limits(r, cost_units=1)
    assert ex.value.status_code == 429

```


===== FILE: tests/services/test_mismatch_service.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/services/test_mismatch_service.py |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


"""
PL: Testy jednostkowe / integracyjne modułu.
EN: Module test suite (unit/integration).
"""

# +-------------------------------------------------------------+
# | CERTEUS - Tests: Mismatch Service                           |
# +-------------------------------------------------------------+
from services.mismatch_service.models import ResolutionType, TicketResolution
from services.mismatch_service.service import MismatchService


def test_create_and_resolve_ticket():
    svc = MismatchService()
    t = svc.create_ticket(
        case_id="case-001",
        formula_str="p -> q",
        results={"z3": {"status": "sat"}, "cvc5": {"status": "unsat"}},
    )
    assert t.ticket_id.startswith("MM-")
    assert t.priority in ("high", "critical", "medium", "low")

    res = TicketResolution(
        ticket_id=t.ticket_id,
        resolution_type=ResolutionType.HUMAN_OVERRIDE,
        chosen_result="sat",
        notes="Expert decision",
        resolved_by="tester",
        confidence=0.8,
    )
    t2 = svc.resolve_ticket(t.ticket_id, res)
    assert t2.status == "resolved"
    assert t2.chosen_result == "sat"

```


===== FILE: tests/services/test_preview.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  tests/services/test_preview.py                              |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+
# | FILE / PLIK: tests/services/test_preview.py                          |
# | ROLE / ROLA:                                                         |
# |  EN: Integration tests for /v1/preview endpoint (file → preview URL).|
# |  PL: Testy integracyjne endpointu /v1/preview (plik → URL podglądu). |
# +=====================================================================+

"""
PL: Testy weryfikują, że endpoint /v1/preview przyjmuje plik (multipart/form-data)
    i zwraca JSON z kluczem `url` wskazującym ścieżkę podglądu w `/static/previews/...`.

EN: Tests verify that /v1/preview accepts a file (multipart/form-data) and returns
    JSON with a `url` pointing to a preview path under `/static/previews/...`.
"""

from __future__ import annotations

from pathlib import Path

from fastapi.testclient import TestClient

import services.api_gateway.main as api_main


def test_health_ok() -> None:
    client = TestClient(api_main.app)
    r = client.get("/health")
    assert r.status_code == 200
    assert r.json().get("status") == "ok"


def test_static_app_mount() -> None:
    client = TestClient(api_main.app)
    r = client.get("/app/proof_visualizer/index.html")
    assert r.status_code in (
        200,
        404,
    )  # mount działa; plik może nie istnieć w teście CI


def test_preview_upload_roundtrip(tmp_path: Path) -> None:
    client = TestClient(api_main.app)
    sample = tmp_path / "sample.txt"
    sample.write_text("hello", encoding="utf-8")
    with sample.open("rb") as fh:
        r = client.post("/v1/preview", files={"file": ("sample.txt", fh, "text/plain")})
    assert r.status_code == 200
    url = r.json().get("url")
    assert isinstance(url, str) and url.startswith("/static/previews/")

    rel = url.removeprefix("/static/")
    saved = Path("static") / rel
    assert saved.exists()
    saved.unlink(missing_ok=True)

```


===== FILE: tests/services/test_schemas.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/services/test_schemas.py          |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+

# |                          CERTEUS                            |

# +-------------------------------------------------------------+

# | FILE: tests/services/test_schemas.py                      |

# | ROLE: Project module.                                       |

# | PLIK: tests/services/test_schemas.py                      |

# | ROLA: Moduł projektu.                                       |

# +-------------------------------------------------------------+


"""



PL: Moduł CERTEUS – uzupełnij opis funkcjonalny.



EN: CERTEUS module – please complete the functional description.



"""


# +-------------------------------------------------------------+


# |                CERTEUS - Schema Contract Tests              |


# +-------------------------------------------------------------+


# | PLIK / FILE: tests/services/test_schemas.py                 |


# | ROLA / ROLE: Sprawdza poprawność przykładowych danych        |


# |             względem 'Świętej Trójcy' schematów.            |


# +-------------------------------------------------------------+


# | STYLE: PL-first, headers & notes dual-language (PL/EN).     |


# +-------------------------------------------------------------+

from __future__ import annotations

# === IMPORTY / IMPORTS ===
import json
from pathlib import Path
from typing import Any, Final, Protocol

import pytest
from jsonschema import Draft7Validator, FormatChecker
from jsonschema.exceptions import ValidationError

# === ALIASY TYPÓW / TYPE ALIASES ===


Schema = dict[str, Any]


JSONObj = dict[str, Any]


SCHEMA_DIR: Final[Path] = Path("schemas")


# === PROTOKÓŁ WALIDATORA / VALIDATOR PROTOCOL ===


class _ValidatorProtocol(Protocol):
    """



    PL: Minimalny interfejs wymagany od walidatora.



    EN: Minimal interface required from a validator.



    """

    def validate(self, instance: Any) -> None: ...


def load_schema(name: str) -> Schema:
    """



    PL: Ładuje i syntaktycznie weryfikuje schemat JSON (Draft7).



    EN: Loads and syntactically checks a JSON schema (Draft7).



    """

    path = SCHEMA_DIR / name

    with path.open("r", encoding="utf-8") as f:
        schema: Schema = json.load(f)

    Draft7Validator.check_schema(schema)

    return schema


def assert_valid(instance: JSONObj, schema: Schema) -> None:
    """



    PL: Waliduje instancję względem danego schematu (z FormatCheckerem).



    EN: Validates the instance against the given schema (with FormatChecker).



    """

    validator: _ValidatorProtocol = Draft7Validator(schema, format_checker=FormatChecker())  # type: ignore[assignment]

    validator.validate(instance)  # pyright: ignore[reportUnknownMemberType]


def assert_invalid(instance: JSONObj, schema: Schema) -> None:
    """



    PL: Oczekuje błędu walidacji.



    EN: Expects validation error.



    """

    validator: _ValidatorProtocol = Draft7Validator(schema, format_checker=FormatChecker())  # type: ignore[assignment]

    with pytest.raises(ValidationError):
        validator.validate(instance)  # pyright: ignore[reportUnknownMemberType]


# === FIXTURE’Y / FIXTURES ===


@pytest.fixture(scope="module")
def S_PROVENANCE() -> Schema:
    return load_schema("provenance_receipt_v1.json")


@pytest.fixture(scope="module")
def S_ANSWER() -> Schema:
    return load_schema("answer_contract_v1.json")


@pytest.fixture(scope="module")
def S_PCA2() -> Schema:
    return load_schema("pca2_v1.json")


# === TESTY: PROVENANCE ===


def test_provenance_valid(S_PROVENANCE: Schema) -> None:
    ok: JSONObj = {
        "case_id": "RS-DOM-vs-Stasikowski",
        "receipt_id": "11111111-2222-3333-4444-555555555555",
        "inputs": {
            "lexlog_rule_version": "pl.lexlog/1.0.0",
            "assumptions_hash": "f" * 64,
            "question_hash": "a" * 64,
        },
        "solvers": {"z3": {"status": "ok", "runtime_ms": 12}, "cvc5": {"status": "ok"}},
        "mismatch": False,
        "final_hash": "0" * 64,
        "timestamp": "2025-08-14T10:00:00Z",
    }

    assert_valid(ok, S_PROVENANCE)


def test_provenance_invalid_missing_required(S_PROVENANCE: Schema) -> None:
    bad: JSONObj = {
        "inputs": {"lexlog_rule_version": "x", "assumptions_hash": "f" * 64},
        "solvers": {},
        "mismatch": True,
        "final_hash": "0" * 64,
        "timestamp": "2025-08-14T10:00:00Z",
    }

    assert_invalid(bad, S_PROVENANCE)


# === TESTY: ANSWER CONTRACT ===


def test_answer_valid(S_ANSWER: Schema) -> None:
    ok: JSONObj = {
        "answer_id": "aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee",
        "case_id": "RS-DOM-vs-Stasikowski",
        "question": {"text": "Czy §10 ust. 1 pkt 3 ma zastosowanie?", "lang": "pl"},
        "answer": {"text": "Tak/Nie + uzasadnienie...", "lang": "pl", "hash": "1" * 64},
        "citations": [
            {
                "type": "statute",
                "label": "KC art. 647¹",
                "ref": "Dz.U....",
                "locator": "art. 647(1) §2",
            }
        ],
        "metrics": {"confidence": 0.92, "latency_ms": 120},
        "model": {
            "provider": "LEXENITH",
            "name": "GPT-5 Thinking",
            "version": "2025.08",
        },
        "provenance": {"receipt_id": "11111111-2222-3333-4444-555555555555"},
        "timestamps": {"created_at": "2025-08-14T10:01:00Z"},
    }

    assert_valid(ok, S_ANSWER)


def test_answer_invalid_confidence_range(S_ANSWER: Schema) -> None:
    bad: JSONObj = {
        "answer_id": "aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee",
        "case_id": "X",
        "question": {"text": "foo"},
        "answer": {"text": "bar"},
        "timestamps": {"created_at": "2025-08-14T10:01:00Z"},
        "model": {"provider": "LEXENITH", "name": "GPT-5 Thinking"},
        "metrics": {"confidence": 1.5},
    }

    assert_invalid(bad, S_ANSWER)


# === TESTY: PCA² ===


def test_pca2_valid(S_PCA2: Schema) -> None:
    ok: JSONObj = {
        "case_id": "RS-DOM-vs-Stasikowski",
        "policy": ["lexenith.secure.v1", "legal.pl.civil.kc"],
        "constraints": [{"name": "no_private_data", "expression": "PII==False", "verdict": "pass"}],
        "assumptions": [{"name": "ryczalt", "value": "tak"}],
        "attestations": [
            {
                "subject": "answer#aaaaaaaa",
                "by": "auditor.bot",
                "result": "pass",
                "at": "2025-08-14T10:05:00Z",
            }
        ],
        "audit_trail": [
            {
                "type": "constraint_eval",
                "at": "2025-08-14T10:05:01Z",
                "actor": "cerber",
                "message": "OK",
            }
        ],
        "overall_status": "pass",
        "final_hash": "2" * 64,
    }

    assert_valid(ok, S_PCA2)


def test_pca2_invalid_status(S_PCA2: Schema) -> None:
    bad: JSONObj = {"case_id": "X", "overall_status": "unknown"}

    assert_invalid(bad, S_PCA2)

```


===== FILE: tests/services/test_sipp.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/services/test_sipp.py             |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                         CERTEUS                             |
# |      Core Engine for Reliable & Unified Systems             |
# +-------------------------------------------------------------+
# | FILE: tests/services/test_sipp.py                           |
# | ROLE: Integration tests for SIPP Indexer endpoint.          |
# +-------------------------------------------------------------+

"""
PL: Testuje endpoint /v1/sipp/snapshot/{act_id}.
EN: Tests the /v1/sipp/snapshot/{act_id} endpoint.
"""

from __future__ import annotations

import json
from pathlib import Path

from fastapi.testclient import TestClient

from services.api_gateway.main import app

client = TestClient(app)


def test_get_snapshot_endpoint_success() -> None:
    act_id = "kk-art-286"
    resp = client.get(f"/v1/sipp/snapshot/{act_id}")
    assert resp.status_code == 200
    data = resp.json()
    assert data["act_id"] == act_id
    assert data["version_id"] == "2023-10-01"
    assert data["source_url"]
    assert data["text_sha256"].startswith("sha256:")
    assert "snapshot_timestamp" in data


def test_get_snapshot_with_at_param() -> None:
    act_id = "kk-art-286"
    resp = client.get(f"/v1/sipp/snapshot/{act_id}?at=2024-11-24")
    assert resp.status_code == 200
    data = resp.json()
    assert data["act_id"] == act_id
    # Stub ignores 'at', but API must accept the param gracefully.
    assert data["version_id"] == "2023-10-01"


def test_index_isap_writes_snapshot_file(tmp_path: Path) -> None:
    from services.sipp_indexer_service.index_isap import index_act

    p = index_act("kk-art-286", out_dir=tmp_path)  # nie piszemy do repo podczas testu
    assert p.exists()

    data = json.loads(p.read_text(encoding="utf-8"))
    assert data["act_id"] == "kk-art-286"
    assert data["text_sha256"].startswith("sha256:")
    assert "snapshot_timestamp" in data
    assert "_certeus" in data and "snapshot_timestamp_utc" in data["_certeus"]

```


===== FILE: tests/services/test_verify_mismatch.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/services/test_verify_mismatch.py  |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                          CERTEUS                            |
# +-------------------------------------------------------------+
# | FILE: tests/services/test_verify_mismatch.py                |
# | ROLE: Ensures mismatch maps to HTTP 409 requires_human.     |
# | PLIK: tests/services/test_verify_mismatch.py                |
# | ROLA: Gwarantuje mapowanie rozjazdu na HTTP 409.            |
# +-------------------------------------------------------------+
"""
PL: Test symuluje rozbieżność rdzeni i sprawdza odpowiedź 409.
EN: Test simulates core mismatch and checks 409 response.
"""

# === IMPORTY / IMPORTS ===
from fastapi.testclient import TestClient

from services.api_gateway.main import app


# === TEST / TEST ===
def test_verify_returns_409_on_mismatch(monkeypatch):
    """
    PL: Symulowany MismatchError powinien dać 409 + requires_human:true.
    EN: Simulated MismatchError should return 409 + requires_human:true.
    """
    from kernel import truth_engine

    original = truth_engine.DualCoreVerifier.verify

    def fake_verify(self, formula, lang="smt2"):
        from kernel.mismatch_protocol import MismatchError

        raise MismatchError("forced mismatch")

    monkeypatch.setattr(truth_engine.DualCoreVerifier, "verify", fake_verify)
    client = TestClient(app)
    r = client.post("/v1/verify", json={"formula": "(set-logic QF_LIA)", "lang": "smt2"})
    assert r.status_code == 409
    body = r.json()
    assert body["detail"]["requires_human"] is True

    # porządek
    monkeypatch.setattr(truth_engine.DualCoreVerifier, "verify", original)

```


===== FILE: tests/test_adapters_local_impl.py =====
```text
# =============================================================================
#  Tests — Local Adapters stubs
# =============================================================================
#!/usr/bin/env python3
# +=====================================================================+
# |                              CERTEUS                                |
# +=====================================================================+
# | MODULE / MODUŁ: tests/test_adapters_local_impl.py                   |
# | DATE / DATA: 2025-08-17                                             |
# +=====================================================================+
# | ROLE / ROLA:                                                        |
# |  EN: Tests for stubbed adapters (Drive/Preview/OCR/LLM).            |
# |  PL: Testy stubowych adapterów (Drive/Preview/OCR/LLM).             |
# +=====================================================================+

"""
PL: Testy minimalnych, lokalnych implementacji adapterów.
EN: Tests for minimal, local adapter implementations.
"""

from __future__ import annotations

from pathlib import Path

import pytest

from services.ingest_service.adapters.contracts import (
    Attachment,
    Blob,
    LLMRequest,
    OCRRequest,
    PreviewRequest,
)
from services.ingest_service.adapters.local_impl import (
    LocalDriveAdapter,
    StubLLMAdapter,
    StubOCRAdapter,
    StubPreviewAdapter,
)


@pytest.mark.asyncio
async def test_drive_roundtrip(tmp_path: Path) -> None:
    drive = LocalDriveAdapter(base_dir=tmp_path / "static", base_url_prefix="/static")
    data = b"hello"
    saved = await drive.save_bytes(data, filename="x.txt", content_type="text/plain", case_id="caseA")
    assert saved.file_id.endswith(".txt")
    raw = await drive.read_bytes(saved.file_id)
    assert raw == data
    url = await drive.url_for(saved.file_id)
    assert url and url.startswith("/static/")


@pytest.mark.asyncio
async def test_preview_stub_docx_to_pdf(tmp_path: Path) -> None:
    drive = LocalDriveAdapter(base_dir=tmp_path / "static", base_url_prefix="/static")
    preview = StubPreviewAdapter(drive)
    blob = Blob(
        filename="sample.docx",
        content_type=("application/vnd.openxmlformats-officedocument.wordprocessingml.document"),
        data=b"DOCX_BYTES_STUB",
    )
    req = PreviewRequest(blob=blob, case_id="caseB", target_format="application/pdf")
    res1 = await preview.generate(req)
    res2 = await preview.generate(req)
    assert res1.content_type == "application/pdf"
    assert res1.url.startswith("/static/")
    # Deterministic URL (same inputs):
    assert res1.url == res2.url
    # File exists:
    path_rel = res1.url.removeprefix("/static/")
    assert (tmp_path / "static" / path_rel).exists()


@pytest.mark.asyncio
async def test_ocr_stub_returns_page() -> None:
    ocr = StubOCRAdapter()
    blob = Blob(filename="scan.png", content_type="image/png", data=b"\x89PNG...")
    pages = await ocr.extract(OCRRequest(blob=blob, lang_hint="pl+en"))
    pages = list(pages)
    assert len(pages) >= 1
    assert pages[0].index == 0
    assert "filename=scan.png" in pages[0].text


@pytest.mark.asyncio
async def test_llm_stub_deterministic() -> None:
    llm = StubLLMAdapter()
    req = LLMRequest(
        prompt="Check attachments.",
        attachments=[
            Attachment(name="a.txt", kind="text", content="ABC"),
            Attachment(name="p.pdf", kind="preview_url", content="/static/x.pdf"),
        ],
        case_id="caseC",
    )
    res = await llm.analyze(req)
    assert res.status == "ok"
    assert res.model.startswith("ALI-Stub")
    assert "attachments" in res.answer["summary"]
    assert isinstance(res.trace, tuple)

```


===== FILE: tests/test_merkle.py =====
```text
from __future__ import annotations

from hashlib import sha256

from services.ledger_service.cosmic_merkle import anchor_bundle, get_bundle_proof, verify_proof


def _hx(s: str) -> str:
    return sha256(s.encode("utf-8")).hexdigest()


def test_anchor_and_verify_roundtrip() -> None:
    rid = _hx("rid-1")
    bundle = _hx("bundle-1")

    receipt = anchor_bundle(rid, bundle)
    again = get_bundle_proof(rid, bundle)
    assert again is not None
    assert receipt.root == again.root
    assert verify_proof(receipt)
    assert verify_proof(again)

```


===== FILE: tests/test_pco_core.py =====
```text
#!/usr/bin/env python3
# +=====================================================================+
# |                              CERTEUS                                |
# +=====================================================================+
# | MODULE / MODUŁ: tests/test_pco_core.py                               |
# | DATE / DATA: 2025-08-19                                              |
# +=====================================================================+
# | EN: Core PCO tests: bundle hash, Merkle, Ed25519 sign/verify,        |
# |     build-and-verify happy path.                                     |
# | PL: Testy jądra PCO: hash bundla, Merkle, podpis/weryfikacja,        |
# |     ścieżka pozytywna build-and-verify.                              |
# +=====================================================================+

from __future__ import annotations

# ----Bloki----- IMPORTY
import time
from hashlib import sha256

import pytest
from cryptography.exceptions import InvalidSignature
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey

from core.pco import (
    PublicPCO,
    apply_merkle_path,
    canonical_bundle_hash_hex,
    canonical_digest_hex,
    compute_leaf_hex,
    ed25519_verify_b64u,
)


def _hex(s: str) -> str:
    return sha256(s.encode("utf-8")).hexdigest()


def test_kernel_bundle_hash_and_leaf() -> None:
    smt2_hash = _hex("(set-logic ALL)\n(check-sat)")
    lfsc = "(lfsc proof)"
    bundle_hash = canonical_bundle_hash_hex(smt2_hash, lfsc, None)
    leaf = compute_leaf_hex("demo-001", bundle_hash)
    # sanity: długości
    assert len(bundle_hash) == 64
    assert len(leaf) == 64


def test_kernel_canonical_digest_and_sig() -> None:
    sk = Ed25519PrivateKey.generate()
    pk = sk.public_key().public_bytes(encoding=serialization.Encoding.Raw, format=serialization.PublicFormat.Raw)
    smt2_hash = _hex("(set-logic ALL)\n(check-sat)")
    lfsc = "(lfsc proof)"
    drat = None
    bundle_hash = canonical_bundle_hash_hex(smt2_hash, lfsc, drat)
    root = apply_merkle_path(compute_leaf_hex("demo-001", bundle_hash), [])  # MVP: []
    digest = canonical_digest_hex(
        rid="demo-001", smt2_hash_hex=smt2_hash, lfsc_text=lfsc, drat_text=drat, merkle_root_hex=root
    )
    sig = sk.sign(bytes.fromhex(digest))
    ed25519_verify_b64u(pk, __import__("base64").urlsafe_b64encode(sig).rstrip(b"=").decode(), digest)


def test_kernel_build_and_verify() -> None:
    sk = Ed25519PrivateKey.generate()
    pk = sk.public_key().public_bytes(encoding=serialization.Encoding.Raw, format=serialization.PublicFormat.Raw)
    rid = "demo-001"
    smt2_hash = _hex("(set-logic ALL)\n(check-sat)")
    lfsc = "(lfsc proof)"
    # MVP: merkle_proof=[]
    pco = PublicPCO.build_and_sign(
        rid=rid,
        smt2_hash=smt2_hash,
        lfsc=lfsc,
        merkle_proof_raw=[],
        ed25519_private_bytes=sk.private_bytes(
            encoding=serialization.Encoding.Raw,
            format=serialization.PrivateFormat.Raw,
            encryption_algorithm=serialization.NoEncryption(),  # type: ignore[arg-type]
        ),  # raw bytes
        issued_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
    )
    # verify
    pco.verify(ed25519_public_bytes=pk)

    # negatyw: zła sygnatura
    bad = PublicPCO(
        rid=rid,
        smt2_hash=smt2_hash,
        lfsc=lfsc,
        merkle_proof=[],
        signature="A" * 40,
        issued_at=None,
    )
    with pytest.raises(InvalidSignature):
        # verify should raise when signature invalid
        ed25519_verify_b64u(
            pk,
            bad.signature,
            canonical_digest_hex(
                rid=bad.rid,
                smt2_hash_hex=bad.smt2_hash,
                lfsc_text=bad.lfsc,
                drat_text=None,
                merkle_root_hex=compute_leaf_hex(bad.rid, canonical_bundle_hash_hex(bad.smt2_hash, bad.lfsc, None)),
            ),
        )

```


===== FILE: tests/test_pco_public.py =====
```text
#!/usr/bin/env python3
# +=====================================================================+
# |                              CERTEUS                                |
# +=====================================================================+
# | MODULE / MODUŁ: tests/test_pco_public.py                            |
# | DATE / DATA: 2025-08-19                                             |
# +=====================================================================+
# | ROLE / ROLA:                                                        |
# |  EN: API test for /pco/public (happy path + validation).            |
# |  PL: Test API publicznego PCO (ścieżka pozytywna + walidacja).      |
# +=====================================================================+

# ---Bloki----- IMPORTY
from __future__ import annotations

# stdlib
import base64
import json
import time
from hashlib import sha256
from pathlib import Path

# third-party
import pytest
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey
from fastapi.testclient import TestClient

# project
from services.api_gateway.main import app
from services.api_gateway.routers.pco_public import (  # type: ignore
    _canonical_digest_hex,
    compute_leaf_hex,
)

client = TestClient(app)


# ---Bloki----- POMOCNICZE
def _b64u(data: bytes) -> str:
    return base64.urlsafe_b64encode(data).rstrip(b"=").decode("ascii")


def _hex(s: str) -> str:
    return sha256(s.encode("utf-8")).hexdigest()


def _bundle_hash_hex(smt2_hash: str, lfsc_text: str, drat_text: str | None = None) -> str:
    """Musi odzwierciedlać serwerowe _compute_bundle_hash_hex."""
    payload = {"lfsc_sha256": _hex(lfsc_text), "smt2_hash": smt2_hash}
    if drat_text is not None:
        payload["drat_sha256"] = _hex(drat_text)
    blob = json.dumps(payload, separators=(",", ":"), sort_keys=True).encode("utf-8")
    return sha256(blob).hexdigest()


# ---Bloki----- TESTY
def test_get_public_pco_happy_path(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    # GIVEN: środowisko i klucz testowy
    monkeypatch.setenv("PROOF_BUNDLE_DIR", str(tmp_path))
    sk = Ed25519PrivateKey.generate()
    pk_bytes = sk.public_key().public_bytes(
        encoding=serialization.Encoding.Raw,
        format=serialization.PublicFormat.Raw,
    )
    monkeypatch.setenv("ED25519_PUBKEY_HEX", pk_bytes.hex())

    # AND: przygotowany publiczny bundle (MVP, path=[])
    rid = "demo-001"
    smt2_hash = _hex("(set-logic ALL)\n(check-sat)\n")
    lfsc = "(lfsc proof placeholder)"
    pub = {
        "rid": rid,
        "smt2_hash": smt2_hash,
        "lfsc": lfsc,
        # brak 'drat' (optional) w tym teście
        "merkle_proof": [],  # MVP: root==leaf
        "issued_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
    }

    # Oblicz bundle_hash -> liść Merkle -> digest kanoniczny i podpisz
    bundle_hash = _bundle_hash_hex(smt2_hash, lfsc)
    merkle_root = compute_leaf_hex(rid, bundle_hash)  # path == [] ⇒ root == leaf
    digest_hex = _canonical_digest_hex(pub, merkle_root)
    pub["signature"] = _b64u(sk.sign(bytes.fromhex(digest_hex)))

    # Zapisz bundle na FS
    (tmp_path / f"{rid}.json").write_text(json.dumps(pub, ensure_ascii=False), encoding="utf-8")

    # WHEN: pobieramy publiczny PCO
    r = client.get(f"/pco/public/{rid}")
    assert r.status_code == 200, r.text
    body = r.json()

    # THEN: sanity
    assert body["rid"] == rid
    assert "lfsc" in body
    assert "signature" in body


def test_get_public_pco_validation(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv("PROOF_BUNDLE_DIR", str(tmp_path))
    rid = _hex("rid-bad")
    # Błędny JSON (tablica zamiast obiektu)
    (tmp_path / f"{rid}.json").write_text("[]", encoding="utf-8")
    r = client.get(f"/pco/public/{rid}")
    assert r.status_code in (400, 422, 500)

```


===== FILE: tests/truth/test_smt_translator_ext.py =====
```text
#!/usr/bin/env python3
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/truth/test_smt_translator_ext.py  |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+

"""
PL: Testy jednostkowe / integracyjne modułu.
EN: Module test suite (unit/integration).
"""

from __future__ import annotations

import pytest

from kernel.smt_translator import (
    ASTNode,
    compile_bool_ast,
    validate_ast,
)


# ----------------------------------------------------------------------
# Helpers to build small ASTs
# ----------------------------------------------------------------------
def v(name: str) -> ASTNode:
    return {"kind": "var", "name": name}  # type: ignore[typeddict-item]


def not_(arg: ASTNode) -> ASTNode:
    return {"kind": "unary", "op": "NOT", "arg": arg}  # type: ignore[typeddict-item]


def bin_(op: str, left: ASTNode, right: ASTNode) -> ASTNode:
    return {  # type: ignore[typeddict-item]
        "kind": "binary",
        "op": op,
        "left": left,
        "right": right,
    }


def nary_(op: str, *args: ASTNode) -> ASTNode:
    return {  # type: ignore[typeddict-item]
        "kind": "nary",
        "op": op,
        "args": list(args),
    }


# ----------------------------------------------------------------------
# Tests
# ----------------------------------------------------------------------
def test_validate_accepts_minimal_var_and_unary_and_binary():
    ast1: ASTNode = v("a")
    validate_ast(ast1)  # should not raise

    ast2: ASTNode = not_(v("b"))
    validate_ast(ast2)  # should not raise

    ast3: ASTNode = bin_("AND", v("a"), v("b"))
    validate_ast(ast3)  # should not raise


def test_validate_rejects_invalid_ops():
    bad_unary = {"kind": "unary", "op": "NEG", "arg": v("a")}  # type: ignore[typeddict-item]
    with pytest.raises(ValueError):
        validate_ast(bad_unary)  # invalid op

    bad_binary = {"kind": "binary", "op": "NAND", "left": v("a"), "right": v("b")}  # type: ignore[typeddict-item]
    with pytest.raises(ValueError):
        validate_ast(bad_binary)

    bad_nary = {"kind": "nary", "op": "XNOR", "args": [v("a"), v("b")]}  # type: ignore[typeddict-item]
    with pytest.raises(ValueError):
        validate_ast(bad_nary)


def test_compile_populates_symbol_table_for_vars():
    ast = bin_("OR", v("x"), not_(v("y")))
    _, symbols = compile_bool_ast(ast, validate=True)

    assert isinstance(symbols, dict)
    assert set(symbols.keys()) == {"x", "y"}


def test_compile_handles_nary_nodes():
    ast = nary_("AND", v("p"), v("q"), not_(v("r")))
    _, symbols = compile_bool_ast(ast, validate=True)
    assert set(symbols.keys()) == {"p", "q", "r"}

```


===== FILE: tests/truth/test_solvers.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/truth/test_solvers.py             |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                    CERTEUS - Truth Tests                    |
# +-------------------------------------------------------------+
# | PLIK / FILE: tests/truth/test_solvers.py                    |
# | ROLA / ROLE:                                                |
# |  PL: Testy jądra prawdy i generatora artefaktów dowodowych. |
# |  EN: Tests for the truth kernel and proof artifact generator.|
# +-------------------------------------------------------------+

"""
PL: Ten moduł zawiera testy dla generatora dowodów:
    - Test jednostkowy: bezpośrednie wywołanie generate_proofs(...)
    - Test CLI (opcjonalny): wywołanie skryptu przez subprocess, jeśli dostępny jest `uv`.

EN: This module contains tests for the proof generator:
    - Unit test: direct call to generate_proofs(...)
    - Optional CLI test: run the script via subprocess if `uv` is available.
"""

from __future__ import annotations

import shutil
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Literal

import pytest

# Import bezpośrednio z modułu – stabilniej niż subprocess
# Direct import from module – more stable than subprocess
from scripts.generate_proofs import generate_proofs


@pytest.mark.parametrize(
    "formats,mode,expected_files",
    [
        (["drat", "lfsc"], "stub", ["z3.drat", "cvc5.lfsc"]),
        (["drat"], "simulate", ["z3.drat"]),
        (["lfsc"], "simulate", ["cvc5.lfsc"]),
    ],
)
def test_generate_proofs_function_creates_expected_artifacts(
    formats: list[str],
    mode: Literal["stub", "simulate"],
    expected_files: list[str],
) -> None:
    """
    PL: Sprawdza, czy generate_proofs(...) tworzy oczekiwane pliki w danym trybie i formatach.
    EN: Verifies that generate_proofs(...) creates expected files for given mode and formats.
    """
    with tempfile.TemporaryDirectory() as tmpdir:
        out: Path = Path(tmpdir)
        # Wywołanie funkcji bezpośrednio (unit)
        generate_proofs(out, formats, mode)

        # Weryfikacja istnienia plików
        for name in expected_files:
            name_str: str = name
            p: Path = out / name_str
            assert p.exists(), f"PL: Brak pliku: {p} | EN: Missing file: {p}"

        # W trybie simulate sprawdź, że pliki nie są puste
        if mode == "simulate":
            for name in expected_files:
                p: Path = out / name
                size: int = p.stat().st_size
                assert size > 0, f"PL: Pusty plik: {p} | EN: Empty file: {p}"


@pytest.mark.skipif(shutil.which("uv") is None, reason="uv not available on PATH")
def test_generate_proofs_cli_smoke_test() -> None:
    """
    PL: „Dymny” test CLI – uruchamia skrypt przez `uv run python ...` i sprawdza wyjście.
    EN: CLI smoke test – runs the script via `uv run python ...` and checks output.
    """
    with tempfile.TemporaryDirectory() as tmpdir:
        out: Path = Path(tmpdir)
        cmd: list[str] = [
            "uv",
            "run",
            sys.executable,  # aktywny Python z venv
            "scripts/generate_proofs.py",
            "--out",
            str(out),
            "--mode",
            "simulate",
        ]
        res = subprocess.run(cmd, check=True, capture_output=True, text=True)
        stdout: str = res.stdout

        assert ("Created simulated proof with content" in stdout) or ("Created stub proof" in stdout)
        assert (out / "z3.drat").exists()
        assert (out / "cvc5.lfsc").exists()

```


===== FILE: tests/utils/test_console.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tests/utils/test_console.py             |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                          CERTEUS                            |
# +-------------------------------------------------------------+
# | FILE: tests/utils/test_console.py                           |
# | ROLE: Tests for console utilities (ASCII-safe & colors).    |
# | PLIK: tests/utils/test_console.py                           |
# | ROLA: Testy narzędzi konsolowych (ASCII-safe i kolory).     |
# +-------------------------------------------------------------+
"""
PL: Testy funkcji utils.console: ascii_safe, print_safe, info/success/error i bezpieczeństwo ASCII.
EN: Tests for utils.console functions: ascii_safe, print_safe, info/success/error and ASCII safety.
"""

from __future__ import annotations

from utils.console import ascii_safe, error, info, print_safe, success


class _AsciiOnlyStream:
    """Tiny write-capturing stream that only accepts ASCII."""

    def __init__(self) -> None:
        self._encoding = "ascii"
        self._buf: list[str] = []

    @property
    def encoding(self) -> str:  # Protocol dopuszcza Optional[str]
        return self._encoding

    # NAZWA PARAMETRU MUSI BYĆ 's', żeby zgadzała się z Protocol.StreamLike
    def write(self, s: str) -> int:
        # enforce ASCII-only
        s.encode("ascii")
        self._buf.append(s)
        return len(s)

    def flush(self) -> None:  # pragma: no cover
        return

    def getvalue(self) -> str:
        return "".join(self._buf)

    def isatty(self) -> bool:  # pragma: no cover
        return False


def test_ascii_safe_true_for_ascii_stream() -> None:
    s = _AsciiOnlyStream()
    assert ascii_safe(s) is True


def test_print_safe_replaces_non_ascii_on_ascii_stream() -> None:
    s = _AsciiOnlyStream()
    text = "Zażółć gęślą jaźń"
    print_safe(text, stream=s)  # should not raise
    captured = s.getvalue()
    # enforce that output is pure ASCII
    captured.encode("ascii")
    # and likely contains replacements
    assert any(ord(ch) > 127 for ch in text)
    assert "?" in captured or captured != text


def test_info_success_error_prefixes_ascii_stream() -> None:
    s = _AsciiOnlyStream()
    info("hello", stream=s)
    success("world", stream=s)
    error("boom", stream=s)
    out = s.getvalue()
    assert "[INFO] " in out
    assert "[SUCCESS] " in out
    assert "[ERROR] " in out

```


===== FILE: tmp/cvc5.lfsc =====
```text

```


===== FILE: tmp/z3.drat =====
```text

```


===== FILE: tools/fix_certeus_headers.py =====
```text
#!/usr/bin/env python3
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  tools/fix_certeus_headers.py                                |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+

"""
PL: Hurtowy wstrzykiwacz banerów CERTEUS i docstringów modułów (idempotentny).
EN: Bulk injector for CERTEUS banners and module docstrings (idempotent).
"""

from __future__ import annotations

import datetime
import re
from pathlib import Path

# Lista naprawianych plików (z poprzednich runów gate’a)
FILES = [
    "services/api_gateway/app_e2e.py",
    "tests/services/test_mismatch_service.py",
    "services/api_gateway/routers/mismatch.py",
    "services/api_gateway/main.py",
    "services/exporter_service/exporter.py",
    "typings/z3/__init__.py",
    "kernel/e2e_verifier.py",
    "kernel/dual_core/__init__.py",
    "kernel/dual_core/z3_adapter.py",
    "services/ledger_service/ledger.py",
    "services/__init__.py",
    "tests/truth/test_smt_translator_ext.py",
    "tests/services/test_exporter_provenance.py",
    "kernel/truth_engine.py",
    "services/exporter_service/__init__.py",
    # dopełnienia:
    "tests/services/test_ledger.py",
    "tools/fix_certeus_headers.py",
]

BANNER = """# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  {module_path:<60}|
# | DATE:    {today:<60}|
# +=====================================================================+
"""

DOCSTRING_TMPL = '''"""
PL: {pl_desc}
EN: {en_desc}
"""
'''

# Bezpieczny wzorzec na docstring: potrójne " lub ' (symetryczne)
DOCSTRING_NEAR_TOP_RE = re.compile(r'(?ms)^\s*(["\'])\1\1(?P<body>.*?)(\1\1\1)\s*')


def needs_banner(text: str) -> bool:
    return not text.lstrip().startswith("# +=====================================================================")


def needs_docstring(text: str) -> bool:
    head = "\n".join(text.splitlines()[:25])
    return DOCSTRING_NEAR_TOP_RE.match(head) is None


def make_descriptions(p: Path) -> tuple[str, str]:
    name = str(p).replace("\\", "/")
    if "tests/" in name:
        return (
            "Testy jednostkowe / integracyjne modułu.",
            "Module test suite (unit/integration).",
        )
    if "routers/" in name:
        return (
            "Router FastAPI dla usług CERTEUS.",
            "FastAPI router for CERTEUS services.",
        )
    if name.endswith("__init__.py"):
        return ("Pakiet inicjalizacyjny modułu.", "Package initializer.")
    if "ledger" in name:
        return ("Księga pochodzenia (ledger) – logika.", "Provenance ledger – logic.")
    if "exporter" in name:
        return ("Eksport raportów i artefaktów procesu.", "Report/artefact exporter.")
    if "smt_translator" in name:
        return (
            "Translator SMT i powiązana logika.",
            "SMT translator and related logic.",
        )
    if "e2e_verifier" in name:
        return (
            "Weryfikator E2E przepływów CERTEUS.",
            "E2E verifier for CERTEUS flows.",
        )
    if "z3_adapter" in name:
        return ("Adapter dla Z3 i zależności SMT.", "Adapter for Z3 and SMT.")
    return ("Moduł systemu CERTEUS.", "CERTEUS system module.")


def inject_header_and_docstring(path: Path) -> bool:
    text = path.read_text(encoding="utf-8")
    updated = False

    # przygotuj baner
    today = datetime.date.today().isoformat()
    banner = BANNER.format(module_path=str(path).replace("\\", "/")[:60], today=today)

    new_text = text

    # shebang/encoding na górze – zachowaj
    lines = new_text.splitlines(keepends=True)
    i = 0
    if i < len(lines) and lines[i].startswith("#!"):
        i += 1
    if i < len(lines) and lines[i].startswith("# -*- coding:"):
        i += 1
    prefix = "".join(lines[:i])
    rest = "".join(lines[i:])

    # usuń WSZYSTKIE istniejące banery CERTEUS gdziekolwiek
    rest = re.sub(
        r"(?ms)^# \+={69}\+\n(?:# \|.*\n)+# \+={69}\+\n\n?",
        "",
        rest,
    )

    # dodaj nasz jeden kanoniczny pod shebangiem/encodingiem
    rest = banner + rest
    updated = True

    # docstring: zachowaj pierwszy jeśli jest na górze; jeśli nie ma – dodaj
    head = "\n".join(rest.splitlines()[:25])
    if DOCSTRING_NEAR_TOP_RE.match(head) is None:
        pl, en = make_descriptions(path)
        doc = DOCSTRING_TMPL.format(pl_desc=pl, en_desc=en).strip() + "\n\n"
        rest = doc + rest
        updated = True
    else:
        # jeśli po banerze jest WIĘCEJ niż jeden docstring PL/EN pod rząd – zredukuj do jednego
        parts = rest.splitlines(keepends=True)
        pos = 0
        # omiń baner (to 5–6 linii; wyłap marker linii granicznej)
        while pos < len(parts) and parts[pos].startswith("# "):
            pos += 1
        # od 'pos' – zredukuj ewentualne duplikaty docstringów PL/EN
        tail = "".join(parts[pos:])
        m = DOCSTRING_NEAR_TOP_RE.match(tail)
        if m:
            end = m.end()
            tail2 = tail[end:]
            # usuwaj kolejne docstringi PL/EN od razu po sobie
            while True:
                skip = re.match(r"(?ms)^(?:[ \t]*#.*\n|[ \t]*\n)*", tail2)
                s = skip.end() if skip else 0
                m2 = DOCSTRING_NEAR_TOP_RE.match(tail2[s:])
                if m2:
                    body = m2.group("body")
                    if "PL:" in body and "EN:" in body:
                        tail2 = tail2[:s] + tail2[s + m2.end() :]
                        updated = True
                        continue
                break
            rest = "".join(parts[:pos]) + tail[:end] + tail2

    if updated:
        path.write_text(prefix + rest, encoding="utf-8")
    return updated


def main() -> None:
    repo = Path(".").resolve()
    touched = []
    for rel in FILES:
        p = repo / rel
        if not p.exists() or not p.is_file():
            print(f"[skip] {rel} (missing)")
            continue
        if inject_header_and_docstring(p):
            print(f"[fix ] {rel}")
            touched.append(rel)
        else:
            print(f"[ok  ] {rel}")
    print(f"\nDone. Updated: {len(touched)} file(s).")


if __name__ == "__main__":
    main()

```


===== FILE: tools/normalize_certeus_headers.py =====
```text
#!/usr/bin/env python3
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/tools/normalize_certeus_headers.py      |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


"""
PL: Normalizator nagłówków CERTEUS i docstringów modułów.
    - Usuwa wszystkie istniejące banery CERTEUS w pliku i wstawia jeden kanoniczny
      pod shebangiem/encodingiem.
    - Gwarantuje jeden docstring modułu (zachowuje pierwszy; jeśli brak – dodaje PL/EN).
    - Działa idempotentnie; kolejne uruchomienia nie tworzą duplikatów.
    - Domyślnie zachowuje datę z pierwszego znalezionego banera, można wymusić dzisiejszą.

EN: CERTEUS header & module docstring normalizer.
    - Removes all existing CERTEUS banners and inserts a single canonical one
      below shebang/encoding.
    - Ensures a single module docstring (keeps first; if none, adds PL/EN).
    - Idempotent; subsequent runs don't duplicate.
    - Keeps the first banner's DATE by default; can force today's date.
"""

from __future__ import annotations

import argparse
import datetime
import re
from collections.abc import Iterable
from pathlib import Path

BORDER = "# +=====================================================================+"
CERTEUS_LINE = "# |                          CERTEUS                                    |"
MODULE_LABEL = "MODULE:"
DATE_LABEL = "DATE:"

CANONICAL_WIDTH = 60  # padding width inside "| ... |"

EXCLUDE_DIRS = {
    ".git",
    ".hg",
    ".svn",
    ".venv",
    "venv",
    "env",
    "__pycache__",
    "node_modules",
    "dist",
    "build",
    ".mypy_cache",
    ".pytest_cache",
    ".ruff_cache",
    ".idea",
    ".vscode",
}

PY_GLOB = "**/*.py"

BANNER_RE = re.compile(rf"(?ms)^({re.escape(BORDER)}\n(?:# \|.*\n)+{re.escape(BORDER)}\n)")

DATE_LINE_RE = re.compile(r"# \|\s*DATE:\s*(?P<date>.*?)\s*\|")

TRIPLE_QUOTE_RE = re.compile(r'(?ms)^\s*(?P<q>"""|\'\'\')(?P<body>.*?)(?P=q)\s*')


def iter_py_files(root: Path) -> Iterable[Path]:
    for p in root.glob(PY_GLOB):
        if any(part in EXCLUDE_DIRS for part in p.parts):
            continue
        if p.is_file():
            yield p


def extract_banner_date(block: str) -> str | None:
    m = DATE_LINE_RE.search(block)
    if m:
        return m.group("date").strip()
    return None


def remove_all_banners(text: str) -> tuple[str, str | None]:
    """Remove all CERTEUS banner blocks. Return (text_wo_banners, first_date_if_any)."""
    first_date: str | None = None

    def repl(m: re.Match) -> str:
        nonlocal first_date
        block = m.group(1)
        if first_date is None:
            first_date = extract_banner_date(block)
        return ""  # drop this banner

    new_text = BANNER_RE.sub(repl, text)
    return new_text, first_date


def split_shebang_encoding(text: str) -> tuple[str, str]:
    """Return (prefix, rest) where prefix includes shebang/encoding lines."""
    lines = text.splitlines(keepends=True)
    idx = 0
    if idx < len(lines) and lines[idx].startswith("#!"):
        idx += 1
    if idx < len(lines) and lines[idx].startswith("# -*- coding:"):
        idx += 1
    return "".join(lines[:idx]), "".join(lines[idx:])


def build_banner(module_path: str, date_str: str) -> str:
    line_module = f"# | MODULE:  {module_path:<{CANONICAL_WIDTH}}|"
    line_date = f"# | DATE:    {date_str:<{CANONICAL_WIDTH}}|"
    return "\n".join([BORDER, CERTEUS_LINE, BORDER, line_module, line_date, BORDER]) + "\n\n"


def has_module_docstring_near_top(text_after_banner: str) -> tuple[bool, int, int]:
    """
    Detect a module-level docstring near file start (after comments).
    Returns (found, start_idx, end_idx) in char offsets in text_after_banner.
    """
    # Skip initial comment lines and blanks
    pos = 0
    while True:
        m = re.match(r"[ \t]*#.*\n", text_after_banner[pos:])
        if m:
            pos += m.end()
            continue
        m2 = re.match(r"[ \t]*\n", text_after_banner[pos:])
        if m2:
            pos += m2.end()
            continue
        break

    mdoc = TRIPLE_QUOTE_RE.match(text_after_banner[pos:])
    if mdoc:
        start = pos + mdoc.start()
        end = pos + mdoc.end()
        return True, start, end
    return False, -1, -1


def ensure_single_docstring(text_after_banner: str, module_path: str) -> str:
    """
    Keep the first module docstring (if present). Remove any additional PL/EN
    docstrings immediately following it. If none present, insert a generic PL/EN.
    """
    found, start, end = has_module_docstring_near_top(text_after_banner)
    if found:
        # Remove any additional docstrings appearing right after the first (duplicates).
        tail = text_after_banner[end:]
        # Repeatedly strip PL/EN style docstrings at the very top of 'tail'
        while True:
            # skip blanks/comments
            skip = re.match(r"(?ms)^(?:[ \t]*#.*\n|[ \t]*\n)*", tail)
            s = skip.end() if skip else 0
            next_doc = TRIPLE_QUOTE_RE.match(tail[s:])
            if next_doc:
                body = next_doc.group("body")
                if "PL:" in body and "EN:" in body:
                    tail = tail[:s] + tail[s + next_doc.end() :]
                    continue
            break
        return text_after_banner[:end] + tail

    # No docstring → insert canonical PL/EN
    pl_desc, en_desc = make_descriptions(module_path)
    doc = f'"""\nPL: {pl_desc}\nEN: {en_desc}\n"""\n\n'
    return doc + text_after_banner


def make_descriptions(module_path: str) -> tuple[str, str]:
    name = module_path
    if "tests/" in name:
        return (
            "Testy jednostkowe / integracyjne modułu.",
            "Module test suite (unit/integration).",
        )
    if "routers/" in name:
        return (
            "Router FastAPI dla usług CERTEUS.",
            "FastAPI router for CERTEUS services.",
        )
    if name.endswith("__init__.py"):
        return ("Pakiet inicjalizacyjny modułu.", "Package initializer.")
    if "ledger" in name:
        return ("Księga pochodzenia (ledger) – logika.", "Provenance ledger – logic.")
    if "exporter" in name:
        return ("Eksport raportów i artefaktów procesu.", "Report/artefact exporter.")
    if "smt_translator" in name:
        return (
            "Translator SMT i powiązana logika.",
            "SMT translator and related logic.",
        )
    if "e2e_verifier" in name:
        return (
            "Weryfikator E2E przepływów CERTEUS.",
            "E2E verifier for CERTEUS flows.",
        )
    if "z3_adapter" in name:
        return ("Adapter dla Z3 i zależności SMT.", "Adapter for Z3 and SMT.")
    return ("Moduł systemu CERTEUS.", "CERTEUS system module.")


def normalize_file(p: Path, set_date_today: bool, dry_run: bool) -> bool:
    """
    Returns True if file was modified.
    """
    text = p.read_text(encoding="utf-8")

    # 1) Remove all existing banners (capture first DATE)
    text_wo_banners, first_date = remove_all_banners(text)

    # 2) Split out shebang/encoding
    prefix, rest = split_shebang_encoding(text_wo_banners)

    # 3) Insert canonical banner
    module_path = str(p).replace("\\", "/")
    date_str = (
        datetime.date.today().isoformat() if set_date_today else (first_date or datetime.date.today().isoformat())
    )
    banner = build_banner(module_path, date_str)

    # If rest already starts with the same banner, avoid duplication
    if rest.startswith(banner):
        new_rest = rest
    else:
        new_rest = banner + rest

    # 4) Ensure exactly one module docstring
    new_rest = ensure_single_docstring(new_rest, module_path)

    new_text = prefix + new_rest

    if new_text != text:
        if not dry_run:
            p.write_text(new_text, encoding="utf-8")
        return True
    return False


def main() -> None:
    ap = argparse.ArgumentParser(description="Normalize CERTEUS banners and module docstrings across repository.")
    ap.add_argument("--root", default=".", help="Repository root (default: .)")
    ap.add_argument(
        "--set-date",
        choices=["today", "keep"],
        default="keep",
        help="Use today's date for banner DATE or keep existing (default: keep).",
    )
    ap.add_argument(
        "--dry-run",
        action="store_true",
        help="Only report changes, do not write files.",
    )
    args = ap.parse_args()

    root = Path(args.root).resolve()
    set_date_today = args.set_date == "today"

    changed = 0
    total = 0
    for py in iter_py_files(root):
        total += 1
        if normalize_file(py, set_date_today=set_date_today, dry_run=args.dry_run):
            print(f"[fix ] {py}")
            changed += 1
        else:
            # print(f"[ok  ] {py}")
            pass

    print(f"\nDone. Scanned: {total} file(s), updated: {changed} file(s).")


if __name__ == "__main__":
    main()

```


===== FILE: typings/z3/__init__.py =====
```text
#!/usr/bin/env python3
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/typings/z3/__init__.py                  |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+

"""
PL: Pakiet inicjalizacyjny modułu.
EN: Package initializer.
"""

from typing import Any


class ExprRef: ...


class BoolRef(ExprRef): ...


class CheckSatResult: ...


class AstVector:
    def __len__(self) -> int: ...
    def __getitem__(self, i: int) -> ExprRef: ...


class Solver:
    def add(self, *args: Any) -> None: ...
    def check(self, *assumptions: Any) -> CheckSatResult: ...
    def model(self) -> Any: ...


def Bool(name: str, ctx: Any | None = None) -> BoolRef: ...
def BoolVal(val: Any, ctx: Any | None = None) -> BoolRef: ...
def And(*args: Any) -> ExprRef: ...
def Or(*args: Any) -> ExprRef: ...
def Not(a: Any) -> ExprRef: ...
def Implies(a: Any, b: Any) -> ExprRef: ...
def Xor(*args: Any) -> ExprRef: ...
def parse_smt2_string(s: str, decls: Any | None = None) -> AstVector: ...
def get_version_string() -> str: ...


sat: CheckSatResult
unsat: CheckSatResult
unknown: CheckSatResult

```


===== FILE: utils/__init__.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/utils/__init__.py                       |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                          CERTEUS                            |
# +-------------------------------------------------------------+
# | FILE: utils/__init__.py                                     |
# | ROLE: Utils package public surface.                         |
# | PLIK: utils/__init__.py                                     |
# | ROLA: Publiczny interfejs pakietu utils.                    |
# +-------------------------------------------------------------+
"""
PL: Inicjalizacja pakietu narzędziowego; eksportuje najczęściej używane helpery.
EN: Package initializer for utilities; exports commonly used helpers.
"""

from .console import ascii_safe, error, info, print_safe, success  # noqa: F401

__all__ = ["ascii_safe", "print_safe", "info", "success", "error"]

```


===== FILE: utils/console.py =====
```text
# +=====================================================================+
# |                          CERTEUS                                    |
# +=====================================================================+
# | MODULE:  F:/projekty/certeus/utils/console.py                        |
# | DATE:    2025-08-17                                                  |
# +=====================================================================+


# +-------------------------------------------------------------+
# |                          CERTEUS                            |
# +-------------------------------------------------------------+
# | FILE: utils/console.py                                      |
# | ROLE: Console helpers: ASCII-safe printing & colored logs.  |
# | PLIK: utils/console.py                                      |
# | ROLA: Pomocniki konsolowe: druk ASCII-safe i kolorowe logi. |
# +-------------------------------------------------------------+
"""
PL: Funkcje do bezpiecznego wypisywania ASCII oraz proste znaczniki logów
na strumieniach tekstowych (kolorystyczne).
EN: Helpers for ASCII-safe printing and simple colored
log markers on text streams.
"""

from __future__ import annotations

import sys
from typing import Protocol, cast, runtime_checkable


@runtime_checkable
class StreamLike(Protocol):
    @property
    def encoding(self) -> str | None: ...
    def write(self, s: str) -> int: ...
    def flush(self) -> None: ...
    def isatty(self) -> bool: ...


def _normalize_stream(stream: StreamLike | None, *, fallback: object) -> StreamLike:
    """Return a non-None stream that satisfies StreamLike (runtime-checked)."""
    if stream is not None:
        return stream
    # sys.stdout/sys.stderr spełniają protokół w runtime; rzutujemy jawnie.
    return cast(StreamLike, fallback)


def ascii_safe(stream: StreamLike | None = None) -> bool:
    """
    True jeśli strumień obsługuje ASCII/UTF bez problemów kodowania.
    Conservative: brak informacji o kodowaniu => uznaj za „bezpieczny”.
    """
    s = _normalize_stream(stream, fallback=sys.stdout)
    enc = getattr(s, "encoding", None)
    if enc is None:
        return True
    enc_low = enc.lower()
    return enc_low == "ascii" or enc_low.startswith("utf")


def print_safe(text: str, stream: StreamLike | None = None) -> None:
    """
    Wypisz tekst tak, by nie wywalał się na Windowsowych „charmap”.
    Dla strumieni ASCII zamieniamy znaki nie-ASCII na '?'.
    """
    s = _normalize_stream(stream, fallback=sys.stdout)
    enc = getattr(s, "encoding", None)
    out = text
    if enc and enc.lower() == "ascii":
        out = out.encode("ascii", "replace").decode("ascii")
    s.write(out)
    try:
        s.flush()
    except Exception:
        # Faux-stream może nie mieć flush; ignorujemy.
        pass


def _color(prefix: str, code: str, *, stream: StreamLike) -> str:
    """Koloruj prefiks tylko, jeśli TTY; inaczej zwróć zwykły tekst."""
    if getattr(stream, "isatty", lambda: False)():
        return f"\x1b[{code}m{prefix}\x1b[0m "
    return f"{prefix} "


def info(msg: str, stream: StreamLike | None = None) -> None:
    s = _normalize_stream(stream, fallback=sys.stdout)
    prefix = _color("[INFO]", "94", stream=s)
    print_safe(prefix + msg, stream=s)


def success(msg: str, stream: StreamLike | None = None) -> None:
    s = _normalize_stream(stream, fallback=sys.stdout)
    prefix = _color("[SUCCESS]", "92", stream=s)
    print_safe(prefix + msg, stream=s)


def error(msg: str, stream: StreamLike | None = None) -> None:
    s = _normalize_stream(stream, fallback=sys.stderr)
    prefix = _color("[ERROR]", "91", stream=s)
    print_safe(prefix + msg, stream=s)

```
