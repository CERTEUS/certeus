#!/usr/bin/env python3
"""
ðŸ“Š WORLD-CLASS MONITORING SYSTEM
Real-time telemetry, performance analytics, auto-scaling, intelligent alerts
Target: Enterprise-grade observability with predictive scaling
"""

import asyncio
from collections import defaultdict, deque
from dataclasses import dataclass
import logging
import statistics
import threading
import time
from typing import Any

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False


@dataclass
class MetricPoint:
    """Single metric measurement point"""
    timestamp: float
    metric_name: str
    value: float
    tags: dict[str, str]
    unit: str = ""


@dataclass
class AlertRule:
    """Alert rule configuration"""
    rule_id: str
    metric_name: str
    condition: str  # >, <, >=, <=, ==
    threshold: float
    duration_seconds: int = 60
    severity: str = "WARNING"  # INFO, WARNING, CRITICAL, EMERGENCY
    enabled: bool = True


@dataclass
class Alert:
    """Active alert"""
    alert_id: str
    rule_id: str
    metric_name: str
    current_value: float
    threshold: float
    severity: str
    triggered_at: float
    message: str
    resolved: bool = False
    resolved_at: float | None = None


class MetricsCollector:
    """High-performance metrics collection engine"""

    def __init__(self, retention_hours: int = 24):
        self.metrics: dict[str, deque] = defaultdict(lambda: deque(maxlen=retention_hours * 3600))  # 1 point/second
        self.retention_hours = retention_hours
        self.collection_interval = 1.0  # 1 second
        self.running = False
        self.collector_task: asyncio.Task | None = None

        # Performance optimization
        self.metrics_lock = threading.RLock()
        self.batch_buffer: list[MetricPoint] = []
        self.batch_size = 1000

        print("ðŸ“Š High-performance metrics collector initialized")

    async def start_collection(self):
        """Start metrics collection"""
        self.running = True
        self.collector_task = asyncio.create_task(self._collection_loop())
        print("ðŸš€ Metrics collection started")

    async def stop_collection(self):
        """Stop metrics collection"""
        self.running = False
        if self.collector_task:
            self.collector_task.cancel()
        print("ðŸ›‘ Metrics collection stopped")

    def add_metric(self, metric_name: str, value: float, tags: dict[str, str] = None, unit: str = ""):
        """Add metric point (thread-safe, ultra-fast)"""
        point = MetricPoint(
            timestamp=time.time(),
            metric_name=metric_name,
            value=value,
            tags=tags or {},
            unit=unit
        )

        # Batch for performance
        self.batch_buffer.append(point)

        if len(self.batch_buffer) >= self.batch_size:
            self._flush_batch()

    def _flush_batch(self):
        """Flush metrics batch to storage"""
        if not self.batch_buffer:
            return

        with self.metrics_lock:
            for point in self.batch_buffer:
                self.metrics[point.metric_name].append(point)

        self.batch_buffer.clear()

    async def _collection_loop(self):
        """Background metrics collection loop"""
        while self.running:
            # Collect system metrics
            await self._collect_system_metrics()

            # Flush pending batch
            if self.batch_buffer:
                self._flush_batch()

            await asyncio.sleep(self.collection_interval)

    async def _collect_system_metrics(self):
        """Collect system performance metrics"""
        if not HAS_PSUTIL:
            return

        try:
            # CPU metrics
            cpu_percent = psutil.cpu_percent(interval=None)
            self.add_metric("system.cpu.usage", cpu_percent, unit="%")

            # Memory metrics
            memory = psutil.virtual_memory()
            self.add_metric("system.memory.usage", memory.percent, unit="%")
            self.add_metric("system.memory.available", memory.available, unit="bytes")

            # Disk metrics
            disk = psutil.disk_usage('/')
            self.add_metric("system.disk.usage", disk.percent, unit="%")

            # Network metrics
            network = psutil.net_io_counters()
            self.add_metric("system.network.bytes_sent", network.bytes_sent, unit="bytes")
            self.add_metric("system.network.bytes_recv", network.bytes_recv, unit="bytes")

        except Exception as e:
            logging.warning(f"Failed to collect system metrics: {e}")

    def get_latest_value(self, metric_name: str) -> float | None:
        """Get latest value for metric"""
        with self.metrics_lock:
            if metric_name in self.metrics and self.metrics[metric_name]:
                return self.metrics[metric_name][-1].value
        return None

    def get_metric_history(self, metric_name: str, duration_seconds: int = 3600) -> list[MetricPoint]:
        """Get metric history for specified duration"""
        cutoff_time = time.time() - duration_seconds

        with self.metrics_lock:
            if metric_name not in self.metrics:
                return []

            return [
                point for point in self.metrics[metric_name]
                if point.timestamp >= cutoff_time
            ]

    def calculate_statistics(self, metric_name: str, duration_seconds: int = 300) -> dict[str, float]:
        """Calculate statistics for metric"""
        history = self.get_metric_history(metric_name, duration_seconds)

        if not history:
            return {}

        values = [point.value for point in history]

        return {
            'count': len(values),
            'min': min(values),
            'max': max(values),
            'mean': statistics.mean(values),
            'median': statistics.median(values),
            'stdev': statistics.stdev(values) if len(values) > 1 else 0.0,
            'p95': statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values),
            'p99': statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)
        }


class AlertManager:
    """Intelligent alert management system"""

    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.alert_rules: dict[str, AlertRule] = {}
        self.active_alerts: dict[str, Alert] = {}
        self.alert_history: list[Alert] = []

        # Alert suppression (prevent spam)
        self.suppression_rules: dict[str, float] = {}  # rule_id -> last_trigger_time
        self.min_alert_interval = 300  # 5 minutes between same alerts

        self.running = False
        self.evaluation_task: asyncio.Task | None = None

        print("ðŸ“Š Intelligent alert manager initialized")

    def add_alert_rule(self, rule: AlertRule):
        """Add alert rule"""
        self.alert_rules[rule.rule_id] = rule
        print(f"âœ… Alert rule added: {rule.rule_id} ({rule.metric_name} {rule.condition} {rule.threshold})")

    async def start_alerting(self):
        """Start alert evaluation"""
        self.running = True
        self.evaluation_task = asyncio.create_task(self._evaluation_loop())
        print("ðŸš¨ Alert evaluation started")

    async def stop_alerting(self):
        """Stop alert evaluation"""
        self.running = False
        if self.evaluation_task:
            self.evaluation_task.cancel()
        print("ðŸ›‘ Alert evaluation stopped")

    async def _evaluation_loop(self):
        """Alert evaluation loop"""
        while self.running:
            for rule in self.alert_rules.values():
                if rule.enabled:
                    await self._evaluate_rule(rule)

            await asyncio.sleep(10)  # Evaluate every 10 seconds

    async def _evaluate_rule(self, rule: AlertRule):
        """Evaluate single alert rule"""
        # Get recent metrics
        history = self.metrics_collector.get_metric_history(
            rule.metric_name,
            rule.duration_seconds
        )

        if not history:
            return

        # Check if condition is met consistently
        violation_count = 0
        total_points = len(history)

        for point in history:
            if self._check_condition(point.value, rule.condition, rule.threshold):
                violation_count += 1

        # Trigger alert if >80% of points violate condition
        violation_rate = violation_count / total_points if total_points > 0 else 0

        if violation_rate > 0.8:
            await self._trigger_alert(rule, history[-1].value)
        else:
            await self._resolve_alert(rule)

    def _check_condition(self, value: float, condition: str, threshold: float) -> bool:
        """Check if value meets condition"""
        if condition == ">":
            return value > threshold
        elif condition == "<":
            return value < threshold
        elif condition == ">=":
            return value >= threshold
        elif condition == "<=":
            return value <= threshold
        elif condition == "==":
            return abs(value - threshold) < 0.001
        return False

    async def _trigger_alert(self, rule: AlertRule, current_value: float):
        """Trigger alert"""
        # Check suppression
        last_trigger = self.suppression_rules.get(rule.rule_id, 0)
        if time.time() - last_trigger < self.min_alert_interval:
            return

        alert_id = f"{rule.rule_id}-{int(time.time())}"

        alert = Alert(
            alert_id=alert_id,
            rule_id=rule.rule_id,
            metric_name=rule.metric_name,
            current_value=current_value,
            threshold=rule.threshold,
            severity=rule.severity,
            triggered_at=time.time(),
            message=f"{rule.metric_name} is {current_value:.2f} (threshold: {rule.threshold:.2f})"
        )

        self.active_alerts[alert_id] = alert
        self.alert_history.append(alert)
        self.suppression_rules[rule.rule_id] = time.time()

        print(f"ðŸš¨ ALERT [{rule.severity}]: {alert.message}")

    async def _resolve_alert(self, rule: AlertRule):
        """Resolve alerts for rule"""
        alerts_to_resolve = [
            alert for alert in self.active_alerts.values()
            if alert.rule_id == rule.rule_id and not alert.resolved
        ]

        for alert in alerts_to_resolve:
            alert.resolved = True
            alert.resolved_at = time.time()
            del self.active_alerts[alert.alert_id]
            print(f"âœ… Alert resolved: {alert.message}")

    def get_active_alerts(self) -> list[Alert]:
        """Get all active alerts"""
        return list(self.active_alerts.values())

    def get_alert_summary(self) -> dict[str, int]:
        """Get alert summary by severity"""
        summary = defaultdict(int)
        for alert in self.active_alerts.values():
            summary[alert.severity] += 1
        return dict(summary)


class AutoScaler:
    """Intelligent auto-scaling based on metrics"""

    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.scaling_rules: dict[str, dict[str, Any]] = {}
        self.current_scale = 1.0
        self.min_scale = 0.1
        self.max_scale = 10.0

        # Scaling history for trend analysis
        self.scaling_history = deque(maxlen=100)

        self.running = False
        self.scaler_task: asyncio.Task | None = None

        print("ðŸ“Š Intelligent auto-scaler initialized")

    def add_scaling_rule(self, metric_name: str, scale_up_threshold: float, scale_down_threshold: float):
        """Add auto-scaling rule"""
        self.scaling_rules[metric_name] = {
            'scale_up_threshold': scale_up_threshold,
            'scale_down_threshold': scale_down_threshold,
            'last_scaling_time': 0,
            'cooldown_seconds': 300  # 5 minutes cooldown
        }
        print(f"âœ… Scaling rule added for {metric_name}")

    async def start_scaling(self):
        """Start auto-scaling"""
        self.running = True
        self.scaler_task = asyncio.create_task(self._scaling_loop())
        print("âš¡ Auto-scaling started")

    async def stop_scaling(self):
        """Stop auto-scaling"""
        self.running = False
        if self.scaler_task:
            self.scaler_task.cancel()
        print("ðŸ›‘ Auto-scaling stopped")

    async def _scaling_loop(self):
        """Auto-scaling evaluation loop"""
        while self.running:
            for metric_name, rule in self.scaling_rules.items():
                await self._evaluate_scaling(metric_name, rule)

            await asyncio.sleep(30)  # Evaluate every 30 seconds

    async def _evaluate_scaling(self, metric_name: str, rule: dict[str, Any]):
        """Evaluate scaling for specific metric"""
        # Check cooldown
        if time.time() - rule['last_scaling_time'] < rule['cooldown_seconds']:
            return

        # Get recent metric statistics
        stats = self.metrics_collector.calculate_statistics(metric_name, 300)  # 5 minutes

        if not stats:
            return

        current_value = stats.get('p95', 0)  # Use 95th percentile

        # Determine scaling action
        if current_value > rule['scale_up_threshold']:
            new_scale = min(self.current_scale * 1.5, self.max_scale)
            if new_scale != self.current_scale:
                await self._apply_scaling(new_scale, f"Scale up due to {metric_name}={current_value:.2f}")
                rule['last_scaling_time'] = time.time()

        elif current_value < rule['scale_down_threshold']:
            new_scale = max(self.current_scale * 0.8, self.min_scale)
            if new_scale != self.current_scale:
                await self._apply_scaling(new_scale, f"Scale down due to {metric_name}={current_value:.2f}")
                rule['last_scaling_time'] = time.time()

    async def _apply_scaling(self, new_scale: float, reason: str):
        """Apply scaling decision"""
        old_scale = self.current_scale
        self.current_scale = new_scale

        # Record scaling event
        scaling_event = {
            'timestamp': time.time(),
            'old_scale': old_scale,
            'new_scale': new_scale,
            'reason': reason
        }
        self.scaling_history.append(scaling_event)

        print(f"âš¡ SCALING: {old_scale:.2f} -> {new_scale:.2f} ({reason})")

        # In real system, this would trigger actual scaling (e.g., Kubernetes HPA)
        # For now, we just simulate the scaling decision

    def get_scaling_status(self) -> dict[str, Any]:
        """Get current scaling status"""
        return {
            'current_scale': self.current_scale,
            'min_scale': self.min_scale,
            'max_scale': self.max_scale,
            'recent_events': list(self.scaling_history)[-5:]  # Last 5 events
        }


class WorldClassMonitoringSystem:
    """
    ðŸ“Š World-class monitoring system
    Enterprise-grade observability with predictive capabilities
    """

    def __init__(self):
        # Core components
        self.metrics_collector = MetricsCollector(retention_hours=24)
        self.alert_manager = AlertManager(self.metrics_collector)
        self.auto_scaler = AutoScaler(self.metrics_collector)

        # Dashboard data
        self.dashboard_metrics = {}
        self.running = False

        # Performance tracking
        self.monitoring_start_time = 0.0

        print("ðŸ“Š World-class monitoring system initialized")

    async def start_monitoring(self):
        """Start complete monitoring system"""
        print("ðŸš€ Starting world-class monitoring system...")

        self.running = True
        self.monitoring_start_time = time.time()

        # Start all components
        await self.metrics_collector.start_collection()
        await self.alert_manager.start_alerting()
        await self.auto_scaler.start_scaling()

        # Set up default alert rules
        self._setup_default_alerts()

        # Set up auto-scaling rules
        self._setup_auto_scaling()

        print("âœ… World-class monitoring system started")

    async def stop_monitoring(self):
        """Stop monitoring system"""
        print("ðŸ›‘ Stopping world-class monitoring system...")

        self.running = False

        # Stop all components
        await self.metrics_collector.stop_collection()
        await self.alert_manager.stop_alerting()
        await self.auto_scaler.stop_scaling()

        print("âœ… Monitoring system stopped")

    def _setup_default_alerts(self):
        """Set up default alert rules"""
        # System resource alerts
        self.alert_manager.add_alert_rule(AlertRule(
            rule_id="high_cpu",
            metric_name="system.cpu.usage",
            condition=">",
            threshold=85.0,
            duration_seconds=300,
            severity="WARNING"
        ))

        self.alert_manager.add_alert_rule(AlertRule(
            rule_id="high_memory",
            metric_name="system.memory.usage",
            condition=">",
            threshold=90.0,
            duration_seconds=180,
            severity="CRITICAL"
        ))

        # Performance alerts
        self.alert_manager.add_alert_rule(AlertRule(
            rule_id="low_throughput",
            metric_name="application.throughput",
            condition="<",
            threshold=1000.0,
            duration_seconds=300,
            severity="WARNING"
        ))

    def _setup_auto_scaling(self):
        """Set up auto-scaling rules"""
        # Scale based on CPU usage
        self.auto_scaler.add_scaling_rule("system.cpu.usage", 75.0, 30.0)

        # Scale based on throughput
        self.auto_scaler.add_scaling_rule("application.throughput", 8000.0, 2000.0)

    def record_application_metric(self, metric_name: str, value: float, tags: dict[str, str] = None):
        """Record application-specific metric"""
        self.metrics_collector.add_metric(f"application.{metric_name}", value, tags)

    def get_real_time_dashboard(self) -> dict[str, Any]:
        """Get real-time dashboard data"""
        # System metrics
        system_metrics = {
            'cpu_usage': self.metrics_collector.get_latest_value("system.cpu.usage") or 0,
            'memory_usage': self.metrics_collector.get_latest_value("system.memory.usage") or 0,
            'disk_usage': self.metrics_collector.get_latest_value("system.disk.usage") or 0
        }

        # Application metrics
        app_metrics = {
            'throughput': self.metrics_collector.get_latest_value("application.throughput") or 0,
            'latency': self.metrics_collector.get_latest_value("application.latency") or 0,
            'error_rate': self.metrics_collector.get_latest_value("application.error_rate") or 0
        }

        # Alert summary
        alert_summary = self.alert_manager.get_alert_summary()

        # Scaling status
        scaling_status = self.auto_scaler.get_scaling_status()

        # Uptime
        uptime_seconds = time.time() - self.monitoring_start_time if self.running else 0

        return {
            'timestamp': time.time(),
            'uptime_seconds': uptime_seconds,
            'system_metrics': system_metrics,
            'application_metrics': app_metrics,
            'active_alerts': alert_summary,
            'scaling_status': scaling_status,
            'health_status': self._calculate_health_status(system_metrics, app_metrics, alert_summary)
        }

    def _calculate_health_status(self, system_metrics: dict, app_metrics: dict, alerts: dict) -> str:
        """Calculate overall system health"""
        # Check for critical alerts
        if alerts.get('CRITICAL', 0) > 0 or alerts.get('EMERGENCY', 0) > 0:
            return "CRITICAL"

        # Check system resources
        if (system_metrics.get('cpu_usage', 0) > 90 or
            system_metrics.get('memory_usage', 0) > 95):
            return "DEGRADED"

        # Check warnings
        if alerts.get('WARNING', 0) > 0:
            return "WARNING"

        # Check performance
        if app_metrics.get('throughput', 0) < 1000:
            return "DEGRADED"

        return "HEALTHY"

    def get_performance_report(self) -> dict[str, Any]:
        """Generate comprehensive performance report"""
        report = {
            'report_timestamp': time.time(),
            'monitoring_duration_hours': (time.time() - self.monitoring_start_time) / 3600,
            'metrics_summary': {},
            'alert_summary': {
                'total_alerts': len(self.alert_manager.alert_history),
                'active_alerts': len(self.alert_manager.active_alerts),
                'alert_rate_per_hour': 0
            },
            'scaling_summary': {
                'total_scaling_events': len(self.auto_scaler.scaling_history),
                'current_scale': self.auto_scaler.current_scale
            }
        }

        # Calculate alert rate
        monitoring_hours = report['monitoring_duration_hours']
        if monitoring_hours > 0:
            report['alert_summary']['alert_rate_per_hour'] = len(self.alert_manager.alert_history) / monitoring_hours

        # Key metrics summary
        for metric_name in ['system.cpu.usage', 'system.memory.usage', 'application.throughput']:
            stats = self.metrics_collector.calculate_statistics(metric_name, 3600)  # Last hour
            if stats:
                report['metrics_summary'][metric_name] = stats

        return report


async def create_world_class_monitoring() -> WorldClassMonitoringSystem:
    """Create world-class monitoring system"""
    system = WorldClassMonitoringSystem()
    return system


# Global monitoring system
_monitoring_system: WorldClassMonitoringSystem | None = None


async def get_monitoring_system() -> WorldClassMonitoringSystem:
    """Get global monitoring system"""
    global _monitoring_system

    if _monitoring_system is None:
        _monitoring_system = await create_world_class_monitoring()

    return _monitoring_system


if __name__ == "__main__":
    async def test_world_class_monitoring():
        """Test world-class monitoring system"""
        print("ðŸ“ŠðŸ“ŠðŸ“Š WORLD-CLASS MONITORING TEST ðŸ“ŠðŸ“ŠðŸ“Š")

        system = await get_monitoring_system()
        await system.start_monitoring()

        # Simulate application workload with metrics
        for i in range(60):  # 1 minute test
            # Simulate varying application metrics
            throughput = 5000 + random.randint(-2000, 3000)
            latency = 50 + random.randint(-20, 100)
            error_rate = random.random() * 5  # 0-5% error rate

            system.record_application_metric("throughput", throughput)
            system.record_application_metric("latency", latency)
            system.record_application_metric("error_rate", error_rate)

            # Show dashboard every 10 seconds
            if i % 10 == 0:
                dashboard = system.get_real_time_dashboard()
                print(f"\\nðŸ“Š Dashboard @ {i}s:")
                print(f"   Health: {dashboard['health_status']}")
                print(f"   CPU: {dashboard['system_metrics']['cpu_usage']:.1f}%")
                print(f"   Memory: {dashboard['system_metrics']['memory_usage']:.1f}%")
                print(f"   Throughput: {dashboard['application_metrics']['throughput']:.0f} ops/s")
                print(f"   Scaling: {dashboard['scaling_status']['current_scale']:.2f}x")
                print(f"   Active Alerts: {sum(dashboard['active_alerts'].values())}")

            await asyncio.sleep(1)

        # Generate final report
        report = system.get_performance_report()
        print("\\nðŸ“Š FINAL PERFORMANCE REPORT:")
        print(f"   Monitoring Duration: {report['monitoring_duration_hours']:.2f} hours")
        print(f"   Total Alerts: {report['alert_summary']['total_alerts']}")
        print(f"   Alert Rate: {report['alert_summary']['alert_rate_per_hour']:.1f}/hour")
        print(f"   Scaling Events: {report['scaling_summary']['total_scaling_events']}")
        print(f"   Final Scale: {report['scaling_summary']['current_scale']:.2f}x")

        await system.stop_monitoring()

    import random
    asyncio.run(test_world_class_monitoring())
