# +-------------------------------------------------------------+
# |                          CERTEUS                            |
# +-------------------------------------------------------------+
# | FILE: .github/workflows/ci-gates.yml                      |
# | ROLE: Project YAML manifest.                                |
# | PLIK: .github/workflows/ci-gates.yml                      |
# | ROLA: Manifest YAML projektu.                               |
# +-------------------------------------------------------------+

name: ci-gates

on:
  push:
    branches: [ main ]
  pull_request:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  ci-gates:
    runs-on: ${{ fromJSON(vars.CI_GATES_RUNS_ON || '["self-hosted","linux","docker","build"]') }}
    permissions:
      contents: write
      pull-requests: write
      issues: write
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: |
            requirements.txt
            pyproject.toml
            constraints/**
      - name: Install tools
        run: |
          python -m pip install -U pip wheel setuptools
          # Install project runtime deps
          python -m pip install -e .
          # Install test/dev helpers explicitly used by the suite
          python -m pip install ruff pytest pytest-xdist pytest-asyncio httpx z3-solver hypothesis openapi-spec-validator PyYAML

      - name: Load CI defaults (non-secrets)
        run: |
          python scripts/ci/load_env_defaults.py
      - name: Start mock OTLP receiver (background)
        run: |
          nohup python scripts/otel/mock_otlp.py >/dev/null 2>&1 &
      - name: Decorator split scan (report-only)
        run: |
          python scripts/fix_decorator_split.py --check || true
      - name: Premium Style Gate (sec.21)
        continue-on-error: true
        run: |
          python scripts/check_premium_style.py || true
      - name: Mark Style OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/style_ok.txt
      - name: Ruff Lint (no fix)
        run: |
          python -m ruff check .
      - name: Mark Lint OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/lint_ok.txt
      - name: Bandit security scan (report-only)
        continue-on-error: true
        run: |
          python -m pip install bandit
          # Report-only in ci-gates; enforcement lives in dedicated workflow
          bandit -q -r . -x .venv,venv,clients/web,clients/cli,dist,build || true
      - name: Gitleaks (secrets scan)
        continue-on-error: true
        uses: zricethezav/gitleaks-action@v2.3.7
        with:
          # Report-only for ci-gates; blocking in security-scan.yml
          args: detect --verbose --redact --no-banner --exit-code 1
      - name: Tests
        env:
          PYTEST_ADDOPTS: "-n auto --durations=15 -k 'not test_generate_proofs_cli_smoke_test'"
          OTEL_ENABLED: "1"
          OTEL_EXPORTER_OTLP_ENDPOINT: "http://127.0.0.1:4318"
          FINE_GRAINED_ROLES: "0"
        run: |
          python -m pytest -q
      - name: Mark Tests OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/tests_ok.txt
      - name: Generate SBOM (CycloneDX JSON)
        run: |
          python -m pip install -q cyclonedx-bom || true
          # Prefer cyclonedx-py; fallback to cyclonedx-bom CLI
          python - << 'PY'
          import os, sys, subprocess
          cmds = [
            ['cyclonedx-py','--format','json','--output','sbom.json'],
            ['cyclonedx-bom','-o','sbom.json','-F','json'],
          ]
          ok=False
          for c in cmds:
            try:
              subprocess.check_call(c)
              ok=True; break
            except Exception:
              pass
          if not ok:
            open('sbom.json','w',encoding='utf-8').write('{}')
          print('SBOM ready')
          PY
          test -s sbom.json || echo '{}' > sbom.json
      - name: Build provenance (in-toto style)
        run: |
          python scripts/supply_chain/make_provenance.py
          test -s out/provenance.json
      - name: Validate provenance schema
        run: |
          python scripts/validate_provenance.py
      - name: Enforce supply-chain (deny-by-default)
        env:
          SUPPLY_CHAIN_ENFORCE: '1'
        run: |
          python scripts/gates/supply_chain_enforce.py
      - name: Mark Supply-Chain OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/supply_chain_ok.txt

      - name: Correlation header sample (in-proc)
        run: |
          python - << 'PY'
          from pathlib import Path
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          r = c.get('/health')
          cid = r.headers.get('X-Correlation-ID','')
          tid = r.headers.get('X-Trace-Id','')
          Path('out').mkdir(parents=True, exist_ok=True)
          Path('out/correlation.txt').write_text(f"correlation_id={cid} trace_id={tid}", encoding='utf-8')
          print('Correlation sample:', cid, tid)
          PY

      - name: Shedder info
        run: |
          python - << 'PY'
          import os
          from pathlib import Path
          Path('out').mkdir(parents=True, exist_ok=True)
          info = {
            'enabled': os.getenv('SHED_ENABLE','0'),
            'target_ms': os.getenv('SHED_TARGET_P95_MS','250'),
            'max_rate': os.getenv('SHED_MAX_RATE','0.5'),
          }
          Path('out/shedder_info.txt').write_text('\n'.join(f"{k}={v}" for k,v in info.items()), encoding='utf-8')
          print('Shedder info:', info)
          PY

      - name: Require cosign attestations (optional)
        env:
          REQUIRE_COSIGN_ATTESTATIONS: ${{ vars.REQUIRE_COSIGN_ATTESTATIONS || '0' }}
        run: |
          if [ "${REQUIRE_COSIGN_ATTESTATIONS}" = "1" ]; then
            echo "Requiring cosign attestations: sbom.json.sig, sbom.json.cert"
            python scripts/supply_chain/verify_cosign_artifacts.py --require sbom.json.sig sbom.json.cert
          else
            echo "Cosign attestation requirement disabled (set vars.REQUIRE_COSIGN_ATTESTATIONS=1 to enforce)"
          fi
      - name: Perf Smoke (W11)
        run: |
          python scripts/perf/quick_bench.py --iters 5 --p95-max-ms 250 --out out/perf_bench.json
      - name: Perf Regression Gate (<= +5% vs prev)
        continue-on-error: true
        run: |
          set -e
          # Try to fetch previous perf benchmark from ci-status branch
          git fetch origin ci-status || true
          if git rev-parse --verify origin/ci-status >/dev/null 2>&1; then
            git show origin/ci-status:ci/perf_bench.json > out/prev_perf_bench.json 2>/dev/null || true
          fi
          python - << 'PY'
          import json, sys, pathlib
          repo = pathlib.Path('.').resolve()
          cur_p = repo/'out'/'perf_bench.json'
          prev_p = repo/'out'/'prev_perf_bench.json'
          if not cur_p.exists():
            print('No current perf report found; skipping regression gate')
            sys.exit(0)
          cur = json.loads(cur_p.read_text())
          worst = float(cur.get('worst_p95_ms', 0.0))
          thr_pct = 0.05
          if prev_p.exists():
            prev = json.loads(prev_p.read_text())
            base = float(prev.get('worst_p95_ms', 0.0)) or 1.0
            allowed = base * (1.0 + thr_pct)
            if worst > allowed:
              print(f'Regression: worst p95 {worst:.2f} ms > allowed {allowed:.2f} ms (base {base:.2f} +20%)')
              sys.exit(1)
          print('Perf regression gate: OK')
          PY
      - name: Mark Perf OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/perf_ok.txt

      - name: Boundary report (compute + RTO)
        continue-on-error: true
        run: |
          set -e
          start_ts=$(python - <<'PY'
import time; print(time.time())
PY
          )
          python scripts/gates/compute_boundary_report.py --out out/boundary_report.json || true
          end_ts=$(python - <<'PY'
import time; print(time.time())
PY
          )
          dur=$(python - <<PY
import os
try:
  s=float(os.environ.get('start_ts','0'))
  e=float(os.environ.get('end_ts','0'))
  print(f"{(e-s):.3f}")
except Exception:
  print('0.000')
PY
          )
          echo "$dur" > out/boundary_rto.txt
          # Run gate in report-only mode (no fail in ci-gates)
          python scripts/gates/boundary_rebuild_gate.py --must-zero || true
          echo "Boundary compute RTO(s): $dur"

      - name: DP Policy Gate (OPA/Rego)
        continue-on-error: true
        run: |
          python scripts/gates/dp_policy_gate.py || true
          test -f out/dp_policy_report.json && echo ok || true

      - name: DPIA/DPA validation
        continue-on-error: true
        run: |
          python scripts/compliance/validate_dpia.py || true
          test -f out/dpia_report.json && echo ok || true

      - name: Asset Integrity Gate (PCO public)
        continue-on-error: true
        run: |
          python scripts/gates/asset_integrity_gate.py || true
          test -f out/asset_integrity.json && echo ok || true

      - name: Upload perf report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-bench-${{ github.sha }}
          path: out/perf_bench.json

      - name: Upload snapshot artifacts (coverage/tunneling/corr/devices)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: snapshots-${{ github.sha }}
          path: |
            out/lexqft_coverage_state.json
            out/lexqft_tunnel.json
            out/cfe_qtmp.json
            out/hde_plan.json
            out/qoracle.json
            out/entangler.json
            out/chronosync.json
            out/fin_comm_rs.json
            out/fin_mi.json

      - name: SLO Smoke (in-proc)
        env:
          SLO_MAX_P95_MS: "200"
          SLO_MAX_ERROR_RATE: "0.01"
        run: |
          python scripts/slo_gate/measure_api.py
          python scripts/slo_gate/check_slo.py
      - name: Mark SLO OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/slo_ok.txt

      - name: Canary Gate (progressive readiness)
        env:
          CANARY_COUNT: "50"
          CANARY_MAX_P95_MS: "250"
          CANARY_MAX_ERROR_RATE: "0.01"
        run: |
          python scripts/gates/canary_gate.py --phases 3 --count "$CANARY_COUNT" --p95-max "$CANARY_MAX_P95_MS" --error-rate-max "$CANARY_MAX_ERROR_RATE" --out out/canary.json
      - name: Mark Canary OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/canary_ok.txt

      - name: Right-To-Be-Forgotten smoke + DPIA summary
        run: |
          python scripts/compliance/right_to_be_forgotten_smoke.py
      - name: Mark RTBF OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/rtbf_ok.txt

      - name: Redaction Gate (STRICT clean payload)
        run: |
          python - << 'PY'
          import json, os, sys, subprocess
          clean={"subject":{"name":"Jan TEST"},"content":"Brak wrażliwych danych."}
          env=os.environ.copy(); env['STRICT_REDACTION']='1'
          p=subprocess.run([sys.executable,'scripts/gates/redaction_gate.py'], input=json.dumps(clean), text=True, env=env)
          sys.exit(p.returncode)
          PY
      - name: Mark Redaction OK
        if: success()
        run: |
          mkdir -p out && echo ok > out/redaction_ok.txt

      - name: Append RTBF + DPIA summary to PR comment
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let body = '### Compliance (RTBF + DPIA)\n\n';
            try {
              const rtbf = JSON.parse(fs.readFileSync('reports/rtbf_smoke.json','utf8'));
              body += `RTBF smoke: ${rtbf.ok ? '✅' : '❌'} (detect=${rtbf.pii_detection_rc}, clean_strict=${rtbf.clean_strict_rc})\n`;
            } catch (e) {
              body += 'RTBF smoke: no report\n';
            }
            try {
              const dpia = fs.readFileSync('out/dpia_summary.txt','utf8').trim();
              body += `DPIA: ${dpia}\n`;
            } catch (e) {
              body += 'DPIA: n/a\n';
            }
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body,
            });

      - name: Setup OPA CLI
        uses: open-policy-agent/setup-opa@v2
        with:
          version: latest
      - name: OPA policy tests (roles)
        continue-on-error: true
        run: |
          opa test policies/security -v
      - name: Governance consistency (smoke)
        run: |
          python scripts/validate_governance_consistency.py && echo ok > out/gov_ok.txt

      - name: Redaction Gate (informational)
        env:
          STRICT_REDACTION: "0"
        run: |
          echo '{"subject":{"name":"Jan KOWALSKI"}, "content":"Brak wrażliwych danych."}' | python scripts/gates/redaction_gate.py

      - name: Metrics smoke (/metrics)
        run: |
          python scripts/smokes/metrics_smoke.py
      - name: Mark metrics smoke OK
        if: success()
        run: |
          echo ok > out/metrics_ok.txt

      - name: OpenAPI smoke (/openapi.json)
        run: |
          python scripts/smokes/openapi_smoke.py
      - name: OpenAPI contract parity (runtime vs docs)
        run: |
          python scripts/validate_openapi_contract.py
      - name: Mark OpenAPI contract OK
        if: success()
        run: |
          echo ok > out/openapi_contract_ok.txt
      - name: QTMP smoke (in-proc)
        run: |
          python scripts/smokes/qtm_smoke.py
      - name: QTMP smoke (sequence + expectation)
        run: |
          python scripts/smokes/qtm_seq_expect_smoke.py
      - name: PQ-Crypto Gate (informational)
        continue-on-error: true
        env:
          PQCRYPTO_REQUIRE: ${{ vars.PQCRYPTO_REQUIRE || '0' }}
          PQCRYPTO_READY: ${{ vars.PQCRYPTO_READY || '0' }}
        run: |
          python scripts/gates/pqcrypto_gate.py || true
      - name: LexQFT coverage smoke
        run: |
          python scripts/smokes/lexqft_smoke.py
      - name: LexQFT coverage snapshot (in-proc)
        run: |
          python - << 'PY'
          import json
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          r = c.get('/v1/lexqft/coverage/state')
          r.raise_for_status()
          body = r.json()
          import os
          os.makedirs('out', exist_ok=True)
          with open('out/lexqft_coverage_state.json','w',encoding='utf-8') as f:
            json.dump(body, f)
          print('coverage_gamma=', body.get('coverage_gamma'))
          print('uncaptured_mass=', body.get('uncaptured_mass'))
          PY
      - name: LexQFT tunneling snapshot (low/high energy)
        run: |
          python - << 'PY'
          import json, os
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          low = c.post('/v1/lexqft/tunnel', json={'evidence_energy': 0.6}).json()
          high = c.post('/v1/lexqft/tunnel', json={'evidence_energy': 1.2}).json()
          os.makedirs('out', exist_ok=True)
          with open('out/lexqft_tunnel.json','w',encoding='utf-8') as f:
            json.dump({'low': low, 'high': high}, f)
          print('p_low=', low.get('p_tunnel'), 'p_high=', high.get('p_tunnel'))
          PY
      - name: CFE↔QTMP correlation snapshot (in-proc)
        run: |
          python - << 'PY'
          import json, os
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          # Trigger a QTMP measure to emit correlation and priorities headers
          resp = c.post('/v1/qtm/measure', json={'operator': 'LT', 'source': 'ci-corr'})
          resp.raise_for_status()
          hdr = resp.headers
          corr = hdr.get('X-CERTEUS-PCO-correlation.cfe_qtmp')
          pri_raw = hdr.get('X-CERTEUS-PCO-qtmp.priorities') or '{}'
          try:
              pri = json.loads(pri_raw)
          except Exception:
              pri = {}
          out = {'corr': corr, 'priorities': pri}
          os.makedirs('out', exist_ok=True)
          with open('out/cfe_qtmp.json','w',encoding='utf-8') as f:
              json.dump(out, f)
          print('corr=', corr, 'priorities(L,T)=', pri.get('L'), pri.get('T'))
          PY
      - name: HDE plan snapshot (in-proc)
        run: |
          python - << 'PY'
          import json, os
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          r = c.post('/v1/devices/horizon_drive/plan', json={'case':'ci-hde','target_horizon':0.2})
          r.raise_for_status()
          body = r.json()
          os.makedirs('out', exist_ok=True)
          with open('out/hde_plan.json','w',encoding='utf-8') as f:
              json.dump(body, f)
          print('hde cost_tokens=', body.get('cost_tokens'), 'expected_kappa=', body.get('expected_kappa'))
          PY
      - name: Q-Oracle snapshot (in-proc)
        run: |
          python - << 'PY'
          import json, os
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          r = c.post('/v1/devices/qoracle/expectation', json={'question':'maximize fairness', 'constraints': {'risk': 0.6}})
          r.raise_for_status()
          body = r.json()
          os.makedirs('out', exist_ok=True)
          with open('out/qoracle.json','w',encoding='utf-8') as f:
              json.dump(body, f)
          print('qoracle payoff=', body.get('payoff'))
          PY
      - name: Entangler snapshot (in-proc)
        run: |
          python - << 'PY'
          import json, os
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          r = c.post('/v1/devices/entangle', json={'variables':['A','B','C','D'], 'target_negativity': 0.12})
          r.raise_for_status()
          body = r.json()
          os.makedirs('out', exist_ok=True)
          with open('out/entangler.json','w',encoding='utf-8') as f:
              json.dump(body, f)
          print('entangler achieved_negativity=', body.get('achieved_negativity'))
          PY
      - name: Chronosync snapshot (in-proc)
        run: |
          python - << 'PY'
          import json, os
          from fastapi.testclient import TestClient
          from services.api_gateway.main import app
          c = TestClient(app)
          r = c.post('/v1/devices/chronosync/reconcile', json={'coords': {'case':'ci-chronosync','t': 0}})
          r.raise_for_status()
          body = r.json()
          os.makedirs('out', exist_ok=True)
          with open('out/chronosync.json','w',encoding='utf-8') as f:
              json.dump(body, f)
          print('chronosync reconciled=', body.get('reconciled'))
          PY
      - name: Mark OpenAPI smoke OK
        if: success()
        run: |
          echo ok > out/openapi_ok.txt

      - name: OpenAPI smoke (/openapi.json)
        run: |
          python scripts/smokes/openapi_smoke.py

      - name: Comment PR with perf bench
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let body = '';
            try {
              const data = JSON.parse(fs.readFileSync('out/perf_bench.json', 'utf8'));
              const lines = [];
              lines.push(`### Perf Bench (p95)`);
              lines.push(`Worst p95: ${data.worst_p95_ms.toFixed(2)} ms (threshold ${data.threshold_ms} ms)`);
              lines.push('');
              lines.push('Endpoints:');
              for (const e of data.endpoints) {
                lines.push(`- ${e.method} ${e.path}: p95=${e.p95_ms.toFixed(2)} ms (min=${e.min_ms.toFixed(2)}, max=${e.max_ms.toFixed(2)})`);
              }
              body = lines.join('\n');
            } catch (e) {
              body = 'Perf bench: report not available';
            }
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body,
            });

      - name: Build PR comment summary
        if: github.event_name == 'pull_request' && always()
        run: |
          set -e
          # Try to fetch previous perf benchmark from ci-status branch
          git fetch origin ci-status || true
          if git rev-parse --verify origin/ci-status >/dev/null 2>&1; then
            git show origin/ci-status:ci/perf_bench.json > out/prev_perf_bench.json 2>/dev/null || true
          fi
          python - << 'PY'
          import json, os, pathlib, urllib.request
          repo = pathlib.Path('.').resolve()
          lines = []
          # Perf current
          perf = None
          try:
              perf = json.loads((repo/'out'/'perf_bench.json').read_text())
          except Exception:
              pass
          # Perf previous
          prev = None
          try:
              prev = json.loads((repo/'out'/'prev_perf_bench.json').read_text())
          except Exception:
              pass
          lines.append('### Perf Bench (p95)')
          if perf:
              worst = float(perf.get('worst_p95_ms', 0.0))
              thr = perf.get('threshold_ms')
              lines.append(f"Worst p95: {worst:.2f} ms (threshold {thr} ms)")
              if prev and 'worst_p95_ms' in prev:
                  delta = worst - float(prev.get('worst_p95_ms', 0.0))
                  sign = '+' if delta >= 0 else ''
                  lines.append(f"Δ vs prev: {sign}{delta:.2f} ms")
              lines.append('')
              lines.append('Endpoints:')
              for e in perf.get('endpoints', []):
                  lines.append(f"- {e['method']} {e['path']}: p95={e['p95_ms']:.2f} ms (min={e['min_ms']:.2f}, max={e['max_ms']:.2f})")
              lines.append('')
          else:
              lines.append('Perf bench: report not available')
          # SLO summary with pass/fail (defaults align with step env)
          try:
              slo = json.loads((repo/'out'/'slo.json').read_text())
              p95 = float(slo.get('p95_ms', 0.0))
              er = float(slo.get('error_rate', 0.0))
              max_p95 = float(os.getenv('SLO_MAX_P95_MS', '300'))
              max_er = float(os.getenv('SLO_MAX_ERROR_RATE', '0.01'))
              ok_p95 = p95 <= max_p95
              ok_er = er <= max_er
              ok = ok_p95 and ok_er
              lines.append(f"SLO: p95={p95:.2f} ms (<= {max_p95}), error_rate={er:.4f} (<= {max_er}) => {'✅' if ok else '❌'}")
              lines.append('')
              lines.append('### SLO Status')
              lines.append(f"- p95: {p95:.2f} ms (<= {max_p95}) {'✅' if ok_p95 else '❌'}")
              lines.append(f"- error_rate: {er:.4f} (<= {max_er}) {'✅' if ok_er else '❌'}")
          except Exception:
              lines.append('SLO: report not available')
          # Smokes
          metrics_ok = (repo/'out'/'metrics_ok.txt').exists()
          openapi_ok = (repo/'out'/'openapi_ok.txt').exists()
          gov_ok = (repo/'out'/'gov_ok.txt').exists()
          lines.append(f"Smokes: metrics={'✅' if metrics_ok else '❌'} openapi={'✅' if openapi_ok else '❌'} governance={'✅' if gov_ok else '❌'}")
          # LexQFT coverage summary
          try:
              cov = json.loads((repo/'out'/'lexqft_coverage_state.json').read_text())
              lines.append(f"LexQFT: coverage_gamma={cov.get('coverage_gamma')} uncaptured_mass={cov.get('uncaptured_mass')}")
          except Exception:
              lines.append('LexQFT: coverage summary n/a')
          # Boundary summary (delta_bits + RTO)
          try:
              bnd = json.loads((repo/'out'/'boundary_report.json').read_text()).get('boundary', {})
              delta = bnd.get('delta_bits')
              rto = (repo/'out'/'boundary_rto.txt').read_text().strip() if (repo/'out'/'boundary_rto.txt').exists() else 'n/a'
              lines.append(f"Boundary: delta_bits={delta} RTO_s={rto}")
          except Exception:
              lines.append('Boundary: summary n/a')
          # LexQFT tunneling summary
          try:
              tun = json.loads((repo/'out'/'lexqft_tunnel.json').read_text())
              p_low = (tun.get('low') or {}).get('p_tunnel')
              p_high = (tun.get('high') or {}).get('p_tunnel')
              lines.append(f"LexQFT: tunneling p_low={p_low} p_high={p_high}")
          except Exception:
              lines.append('LexQFT: tunneling summary n/a')
          # CFE↔QTMP correlation
          try:
              cq = json.loads((repo/'out'/'cfe_qtmp.json').read_text())
              corr = cq.get('corr')
              pri = cq.get('priorities') or {}
              lines.append(f"CFE↔QTMP: corr={corr} pri_L={pri.get('L')} pri_T={pri.get('T')}")
          except Exception:
              lines.append('CFE↔QTMP: correlation n/a')
          # HDE plan summary
          try:
              hde = json.loads((repo/'out'/'hde_plan.json').read_text())
              lines.append(f"HDE: cost_tokens={hde.get('cost_tokens')} expected_kappa={hde.get('expected_kappa')}")
          except Exception:
              lines.append('HDE: plan summary n/a')
          # Q-Oracle summary
          try:
              qo = json.loads((repo/'out'/'qoracle.json').read_text())
              lines.append(f"Q-Oracle: payoff={qo.get('payoff')} choice={(qo.get('optimum') or {}).get('choice')}")
          except Exception:
              lines.append('Q-Oracle: summary n/a')
          # Entangler summary
          try:
              ei = json.loads((repo/'out'/'entangler.json').read_text())
              lines.append(f"Entangler: achieved_negativity={ei.get('achieved_negativity')}")
          except Exception:
              lines.append('Entangler: summary n/a')
          # Chronosync summary
          try:
              cs = json.loads((repo/'out'/'chronosync.json').read_text())
              lines.append(f"Chronosync: reconciled={cs.get('reconciled')}")
          except Exception:
              lines.append('Chronosync: summary n/a')
          # KPI table (compact snapshot)
          try:
              def _read(p):
                  try:
                      return json.loads((repo/'out'/p).read_text())
                  except Exception:
                      return {}
              perf = _read('perf_bench.json')
              cov = _read('lexqft_coverage_state.json')
              tun = _read('lexqft_tunnel.json')
              cq = _read('cfe_qtmp.json')
              hde = _read('hde_plan.json')
              qo = _read('qoracle.json')
              ei = _read('entangler.json')
              cs = _read('chronosync.json')
              lines.append('')
              lines.append('### KPI Snapshot')
              lines.append('| Metric | Value |')
              lines.append('|--|--|')
              try:
                  lines.append(f"| p95 worst | {float(perf.get('worst_p95_ms', 0.0)):.2f} ms |")
              except Exception:
                  lines.append('| p95 worst | n/a |')
              lines.append(f"| coverage_gamma | {cov.get('coverage_gamma', 'n/a')} |")
              lines.append(f"| uncaptured_mass | {cov.get('uncaptured_mass', 'n/a')} |")
              p_low = ((tun.get('low') or {}).get('p_tunnel') if tun else None)
              p_high = ((tun.get('high') or {}).get('p_tunnel') if tun else None)
              lines.append(f"| tunneling p_low | {p_low if p_low is not None else 'n/a'} |")
              lines.append(f"| tunneling p_high | {p_high if p_high is not None else 'n/a'} |")
              lines.append(f"| CFE↔QTMP corr | {(cq.get('corr') if cq else 'n/a')} |")
              pri = cq.get('priorities') if cq else {}
              lines.append(f"| pri_L | {pri.get('L', 'n/a')} |")
              lines.append(f"| pri_T | {pri.get('T', 'n/a')} |")
              try:
                  dL = float(pri.get('L', 1.0)) - 1.0
                  dT = float(pri.get('T', 1.0)) - 1.0
                  lines.append(f"| Δ pri_L vs 1.0 | {dL:+.3f} |")
                  lines.append(f"| Δ pri_T vs 1.0 | {dT:+.3f} |")
              except Exception:
                  pass
              lines.append(f"| HDE cost_tokens | {hde.get('cost_tokens', 'n/a')} |")
              lines.append(f"| HDE expected_kappa | {hde.get('expected_kappa', 'n/a')} |")
              lines.append(f"| Q-Oracle payoff | {qo.get('payoff', 'n/a')} |")
              lines.append(f"| Q-Oracle choice | {(qo.get('optimum') or {}).get('choice', 'n/a')} |")
              lines.append(f"| Entangler achieved_negativity | {ei.get('achieved_negativity', 'n/a')} |")
              # Devices SLO table
              lines.append('')
              lines.append('### Devices SLO')
              try:
                  hde_cost = float(hde.get('cost_tokens', 0)) if hde else 0.0
                  hde_ok = hde_cost <= float(os.getenv('DEVICES_HDE_MAX_COST', '60') or 60)
              except Exception:
                  hde_ok = False
              try:
                  qo_pay = float(qo.get('payoff', 0)) if qo else 0.0
                  qo_ok = qo_pay >= float(os.getenv('DEVICES_QORACLE_MIN_PAYOFF', '0.5') or 0.5)
              except Exception:
                  qo_ok = False
              try:
                  ei_neg = float(ei.get('achieved_negativity', 0)) if ei else 0.0
                  ei_ok = ei_neg >= float(os.getenv('DEVICES_ENTANGLER_MIN_NEG', '0.1') or 0.1)
              except Exception:
                  ei_ok = False
              cs_ok = bool(cs.get('reconciled')) if cs else False
              lines.append(f"- HDE cost_tokens<=60: {'✅' if hde_ok else '❌'}")
              lines.append(f"- Q-Oracle payoff>=0.5: {'✅' if qo_ok else '❌'}")
              lines.append(f"- Entangler neg>=0.1: {'✅' if ei_ok else '❌'}")
              lines.append(f"- Chronosync reconciled: {'✅' if cs_ok else '❌'}")
          except Exception:
              pass
          # Local gate ticks
          def _tick(p: str) -> str:
              return '✅' if (repo/'out'/p).exists() else '❌'
          lines.append(f"Gates: style={_tick('style_ok.txt')} lint={_tick('lint_ok.txt')} tests={_tick('tests_ok.txt')} perf={_tick('perf_ok.txt')} slo={_tick('slo_ok.txt')}")
          # Supply-chain summary
          lines.append(f"Supply-chain: {'✅' if (repo/'out'/'supply_chain_ok.txt').exists() else '❌'} (sbom+provenance)")
          # DP Policy summary
          try:
              dp = json.loads((repo/'out'/'dp_policy_report.json').read_text())
              lines.append(f"DP Policy: status={dp.get('status')} used={dp.get('used')}")
          except Exception:
              lines.append('DP Policy: n/a')
          # DPIA/DPA summary
          try:
              dr = json.loads((repo/'out'/'dpia_report.json').read_text())
              miss_dpia = len(dr.get('dpia',{}).get('missing',[]))
              miss_dpa = len(dr.get('dpa',{}).get('missing',[]))
              lines.append(f"DPIA: missing={miss_dpia} DPA: missing={miss_dpa}")
          except Exception:
              lines.append('DPIA/DPA: n/a')
          # Asset integrity summary
          try:
              ai = json.loads((repo/'out'/'asset_integrity.json').read_text())
              lines.append(f"Assets: checked={ai.get('checked')} ok={ai.get('ok')}")
          except Exception:
              lines.append('Assets: n/a')
          # Correlation headers sample
          try:
              corr = (repo/'out'/'correlation.txt').read_text().strip()
              lines.append(f"Correlation: {corr}")
          except Exception:
              lines.append('Correlation: n/a')
          # Shedder info
          try:
              shed = (repo/'out'/'shedder_info.txt').read_text().strip().replace('\n', ', ')
              lines.append(f"Shedder: {shed}")
          except Exception:
              lines.append('Shedder: n/a')
          # PQ-crypto gate (informational)
          try:
              pq = (repo/'out'/'pqcrypto.txt').read_text().strip()
              lines.append(f"PQ-crypto: {pq}")
          except Exception:
              lines.append('PQ-crypto: n/a')
          # Devices snapshots tick
          try:
              def _ok(d: dict, keys: list[str] | None = None) -> bool:
                  return bool(d) and all(k in d for k in (keys or []))
              hde = json.loads((repo/'out'/'hde_plan.json').read_text()) if (repo/'out'/'hde_plan.json').exists() else {}
              qo = json.loads((repo/'out'/'qoracle.json').read_text()) if (repo/'out'/'qoracle.json').exists() else {}
              ei = json.loads((repo/'out'/'entangler.json').read_text()) if (repo/'out'/'entangler.json').exists() else {}
              cs = json.loads((repo/'out'/'chronosync.json').read_text()) if (repo/'out'/'chronosync.json').exists() else {}
              tick = lambda b: '✅' if b else '❌'
              lines.append(
                'Devices: HDE={} Q-Oracle={} Entangler={} Chronosync={}'.format(
                  tick(_ok(hde, ['cost_tokens','expected_kappa'])),
                  tick(_ok(qo, ['payoff','optimum'])),
                  tick(_ok(ei, ['achieved_negativity'])),
                  tick(bool(cs.get('reconciled'))) if cs else '❌'
                )
              )
          except Exception:
              lines.append('Devices: (snapshots not available)')
          # Proof Gate related workflow ticks via GitHub API
          try:
              token = os.getenv('GITHUB_TOKEN')
              repo_slug = os.getenv('GITHUB_REPOSITORY')
              sha = os.getenv('GITHUB_SHA')
              req = urllib.request.Request(
                  f"https://api.github.com/repos/{repo_slug}/actions/runs?head_sha={sha}",
                  headers={"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"},
              )
              with urllib.request.urlopen(req, timeout=10) as resp:  # nosec B310
                  data = json.loads(resp.read().decode('utf-8'))
                  runs = data.get('workflow_runs') or []
                  want = {
                      'Proof Gate': 'pg',
                      'Gauge-Gate': 'gg',
                      'Path-Coverage-Gate': 'pc',
                      'Boundary-Rebuild-Gate': 'br',
                      'asset-guard': 'ag',
                  }
                  status_map = {v: '❌' for v in want.values()}
                  for r in runs:
                      name = r.get('name')
                      concl = r.get('conclusion')
                      key = want.get(name)
                      if key and concl:
                          status_map[key] = '✅' if concl == 'success' else '❌'
                  lines.append("Workflows: PG={} Gauge={} PathCov={} Boundary={} Assets={}".format(
                      status_map['pg'], status_map['gg'], status_map['pc'], status_map['br'], status_map['ag']
                  ))
          except Exception:
              lines.append('Workflows: (status not available)')
          (repo/'out'/'ci_pr_comment.md').write_text('\n'.join(lines), encoding='utf-8')
          PY

      - name: Comment PR with SLO/Smokes/Perf
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let body = 'CI Summary';
            try { body = fs.readFileSync('out/ci_pr_comment.md','utf8'); } catch(e) {}
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body,
            });

      - name: Publish CI status to branch
        continue-on-error: true
        if: always()
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          attempt=0
          max_attempts=5
          until [ $attempt -ge $max_attempts ]; do
            attempt=$((attempt+1))
            echo "[ci-status] Attempt $attempt/$max_attempts"
            # Always refetch latest remote tip
            git fetch origin ci-status || true
            if git rev-parse --verify origin/ci-status >/dev/null 2>&1; then
              git checkout -B ci-status origin/ci-status
            else
              git checkout --orphan ci-status
              git rm -rf . || true
            fi
            mkdir -p ci
            ts="$(date -u +%FT%TZ)"
            printf '%s\n' '{' \
              "  \"repo\": \"${{ github.repository }}\"," \
              "  \"workflow\": \"${{ github.workflow }}\"," \
              "  \"run_id\": \"${{ github.run_id }}\"," \
              "  \"run_number\": \"${{ github.run_number }}\"," \
              "  \"event\": \"${{ github.event_name }}\"," \
              "  \"branch\": \"${{ github.ref_name }}\"," \
              "  \"sha\": \"${{ github.sha }}\"," \
              "  \"status\": \"${{ job.status }}\"," \
              "  \"updated_at\": \"${ts}\"" \
            '}' > ci/status.json
            # Persist latest perf bench for trend comparisons
            if [ -f out/perf_bench.json ]; then
              cp -f out/perf_bench.json ci/perf_bench.json || true
            fi
            # Persist latest snapshots for quick links in PR
            for f in lexqft_coverage_state.json lexqft_tunnel.json cfe_qtmp.json hde_plan.json qoracle.json entangler.json chronosync.json; do
              for f in lexqft_coverage_state.json lexqft_tunnel.json cfe_qtmp.json hde_plan.json qoracle.json entangler.json chronosync.json fin_comm_rs.json fin_mi.json; do
                if [ -f "out/$f" ]; then
                  cp -f "out/$f" "ci/$f" || true
                  git add "ci/$f" || true
                fi
              done
            git add ci/status.json
            git add ci/perf_bench.json || true
            git commit -m "ci: update status to ${{ job.status }} for ${{ github.sha }}" || echo "No changes"
            if git push origin ci-status; then
              echo "[ci-status] Push OK"
              break
            else
              echo "[ci-status] Push failed (likely race). Retrying..."
              sleep 2
            fi
          done
          if [ $attempt -ge $max_attempts ]; then
            echo "[ci-status] Failed to push after $max_attempts attempts"
            exit 1
          fi

      - name: Comment PR with Quick Links
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const repo = process.env.GITHUB_REPOSITORY;
            const runId = process.env.GITHUB_RUN_ID || process.env.GITHUB_RUN_ID || process.env.GITHUB_RUN_NUMBER;
            const baseCi = `https://github.com/${repo}/blob/ci-status/ci`;
          const links = [
              `- Coverage: ${baseCi}/lexqft_coverage_state.json`,
              `- Tunneling: ${baseCi}/lexqft_tunnel.json`,
              `- CFE↔QTMP corr/priorities: ${baseCi}/cfe_qtmp.json`,
              `- HDE plan: ${baseCi}/hde_plan.json`,
              `- Q-Oracle: ${baseCi}/qoracle.json`,
              `- Entangler: ${baseCi}/entangler.json`,
              `- Chronosync: ${baseCi}/chronosync.json`,
              `- FIN R/S: ${baseCi}/fin_comm_rs.json`,
              `- FIN Entanglement MI: ${baseCi}/fin_mi.json`,
              `- Grafana (public): https://www.certeus.pl/grafana`,
              `- CI Run Artifacts: https://github.com/${repo}/actions/runs/${{ github.run_id }}`,
            ];
            const body = ['### Quick Links', ...links].join('\n');
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body,
            });
